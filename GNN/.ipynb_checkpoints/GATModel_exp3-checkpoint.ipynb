{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "742df4e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.loader import DataLoader\n",
    "from torch_geometric.nn import GATConv, global_mean_pool\n",
    "from torch_geometric.data import DataLoader\n",
    "import glob\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "\n",
    "# Define GAT model for batched data\n",
    "class GAT(torch.nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, dropout_p=0.1):\n",
    "        super().__init__()\n",
    "        self.gat = GATConv(in_channels, out_channels, heads=1, concat=True, edge_dim=1)\n",
    "        self.pool = global_mean_pool  # Can also use global_max_pool or global_add_pool\n",
    "        self.dropout = nn.Dropout(p=dropout_p)\n",
    "        self.linear = torch.nn.Linear(out_channels, 1)\n",
    "        self.activation = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x, edge_index, edge_attr, batch):\n",
    "        out, attn_weights = self.gat(x, edge_index, edge_attr, return_attention_weights=True)\n",
    "        out = self.dropout(out)\n",
    "        out = self.pool(out, batch)  # Pool over nodes in each graph\n",
    "        out = self.dropout(out) \n",
    "        out = self.linear(out)\n",
    "        out = self.activation(out)\n",
    "        return out, attn_weights\n",
    "\n",
    "def organize_graph_and_add_weight(file_path, label):\n",
    "    data = np.load(file_path, allow_pickle=True).item()\n",
    "    inverse_distance = data['inverse_distance']\n",
    "    encoded_matrix = data['encoded_matrix']\n",
    "\n",
    "    x = torch.tensor(encoded_matrix, dtype=torch.float32)\n",
    "    adj = torch.tensor(inverse_distance, dtype=torch.float32)\n",
    "\n",
    "    # Normalize adjacency (row-normalize)\n",
    "    adj = adj / (adj.sum(dim=1, keepdim=True) + 1e-8)\n",
    "\n",
    "    # Create edge_index and edge weights\n",
    "    edge_index = (adj > 0).nonzero(as_tuple=False).t()\n",
    "    edge_weight = adj[adj > 0]\n",
    "\n",
    "    y = torch.tensor([label], dtype=torch.float32)\n",
    "    \n",
    "    return Data(x=x, edge_index=edge_index, edge_attr=edge_weight, y=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "78c30293",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, dataloader, criterion, optimizer, device):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    total = 0\n",
    "    correct = 0\n",
    "\n",
    "    for batch in dataloader:\n",
    "        batch = batch.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs, _ = model(batch.x, batch.edge_index, batch.edge_attr, batch.batch)\n",
    "        outputs = outputs.view(-1)  # shape: [batch_size]\n",
    "        loss = criterion(outputs, batch.y.view(-1))\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item() * batch.num_graphs\n",
    "        preds = outputs >= 0.5\n",
    "        correct += (preds == batch.y.view(-1).bool()).sum().item()\n",
    "        total += batch.num_graphs\n",
    "\n",
    "    epoch_loss = running_loss / total\n",
    "    accuracy = correct / total\n",
    "    return epoch_loss, accuracy\n",
    "\n",
    "\n",
    "def validate_model(model, dataloader, criterion, device):\n",
    "    model.eval()\n",
    "    running_loss = 0.0\n",
    "    total = 0\n",
    "    correct = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in dataloader:\n",
    "            batch = batch.to(device)\n",
    "            outputs, _ = model(batch.x, batch.edge_index, batch.edge_attr, batch.batch)\n",
    "            outputs = outputs.view(-1)\n",
    "            loss = criterion(outputs, batch.y.view(-1))\n",
    "            running_loss += loss.item() * batch.num_graphs\n",
    "            preds = outputs >= 0.5\n",
    "            correct += (preds == batch.y.view(-1).bool()).sum().item()\n",
    "            total += batch.num_graphs\n",
    "\n",
    "    validation_loss = running_loss / total\n",
    "    accuracy = correct / total\n",
    "    return validation_loss, accuracy, _\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccfc89c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In validation directory there are 77 positives and 277 fragments\n",
      "Bin 1: Positives = 385, Negatives = 385\n",
      "Bin 2: Positives = 385, Negatives = 385\n",
      "Bin 3: Positives = 385, Negatives = 385\n",
      "Bin 4: Positives = 385, Negatives = 385\n",
      "Bin 5: Positives = 385, Negatives = 385\n",
      "Bin 6: Positives = 385, Negatives = 385\n",
      "Bin 7: Positives = 385, Negatives = 385\n",
      "Bin 8: Positives = 385, Negatives = 385\n",
      "Bin 9: Positives = 385, Negatives = 385\n",
      "Bin 10: Positives = 385, Negatives = 385\n",
      "Bin 11: Positives = 385, Negatives = 385\n",
      "Bin 12: Positives = 385, Negatives = 385\n",
      "Bin 13: Positives = 385, Negatives = 385\n",
      "Bin 14: Positives = 385, Negatives = 385\n",
      "Bin 15: Positives = 385, Negatives = 385\n",
      "Bin 16: Positives = 385, Negatives = 385\n",
      "Bin 17: Positives = 385, Negatives = 385\n",
      "Bin 18: Positives = 385, Negatives = 385\n",
      "Bin 19: Positives = 385, Negatives = 385\n",
      "Bin 20: Positives = 385, Negatives = 385\n",
      "Bin 21: Positives = 385, Negatives = 385\n",
      "Bin 22: Positives = 385, Negatives = 385\n",
      "Bin 23: Positives = 385, Negatives = 385\n",
      "Bin 24: Positives = 385, Negatives = 385\n",
      "Bin 25: Positives = 385, Negatives = 385\n",
      "Bin 26: Positives = 385, Negatives = 385\n",
      "Bin 27: Positives = 385, Negatives = 385\n",
      "Bin 28: Positives = 385, Negatives = 385\n",
      "Bin 29: Positives = 385, Negatives = 385\n",
      "Bin 30: Positives = 385, Negatives = 385\n",
      "Bin 31: Positives = 385, Negatives = 385\n",
      "Bin 32: Positives = 385, Negatives = 385\n",
      "Bin 33: Positives = 385, Negatives = 385\n",
      "Bin 34: Positives = 385, Negatives = 385\n",
      "Bin 35: Positives = 385, Negatives = 385\n",
      "Bin 36: Positives = 385, Negatives = 385\n",
      "Bin 37: Positives = 385, Negatives = 385\n",
      "Bin 38: Positives = 385, Negatives = 385\n",
      "Bin 39: Positives = 385, Negatives = 385\n",
      "Bin 40: Positives = 385, Negatives = 385\n",
      "Bin 41: Positives = 385, Negatives = 385\n",
      "Bin 42: Positives = 385, Negatives = 385\n",
      "Bin 43: Positives = 385, Negatives = 385\n",
      "Bin 44: Positives = 385, Negatives = 385\n",
      "Bin 45: Positives = 385, Negatives = 385\n",
      "Bin 46: Positives = 385, Negatives = 385\n",
      "Bin 47: Positives = 385, Negatives = 385\n",
      "Bin 48: Positives = 385, Negatives = 385\n",
      "Bin 49: Positives = 385, Negatives = 385\n",
      "Bin 50: Positives = 385, Negatives = 385\n"
     ]
    }
   ],
   "source": [
    "# Create a dictionary with file names as keys and label + tensor grid as values\n",
    "positive_grids = glob.glob('../../../Data/SplitData/Cholesterol/cholesterol-separate-graphs-5A_exp3/PositiveWithoutSpies/*.npy')\n",
    "validation_grids = glob.glob('../../../Data/SplitData/Cholesterol/cholesterol-separate-graphs-5A_exp3/Validation_Set/*.npy')\n",
    "\n",
    "positive_graphs = []\n",
    "validation_graphs = []\n",
    "\n",
    "for file in positive_grids:\n",
    "    positive_graphs.append(organize_graph_and_add_weight(file, 1))\n",
    "\n",
    "positive_validation_count = 0\n",
    "unlabeled_validation_count = 0\n",
    "\n",
    "for file in validation_grids:\n",
    "    # Label as negative if \"-f1\" to \"-f5\" is in the filename\n",
    "    if any(f\"-f{i}\" in file for i in range(1, 6)):\n",
    "        label = 0\n",
    "        unlabeled_validation_count += 1\n",
    "        validation_graphs.append(organize_graph_and_add_weight(file, label))\n",
    "    else:\n",
    "        label = 1\n",
    "        positive_validation_count += 1\n",
    "        validation_graphs.append(organize_graph_and_add_weight(file, label))\n",
    "\n",
    "print(\"In validation directory there are\", positive_validation_count, \"positives and\", unlabeled_validation_count, \"fragments\")\n",
    "\n",
    "k = 50\n",
    "bins = []\n",
    "for i in range(1, k + 1):\n",
    "    bin = positive_graphs.copy()\n",
    "    subset_grid = glob.glob(f'../../../Data/SplitData/Cholesterol/cholesterol-separate-graphs-5A_exp3/k_subsets/subset_{i}/*.npy')  # Adjust path as needed\n",
    "    for file in subset_grid:\n",
    "        bin.append(organize_graph_and_add_weight(file, 0))\n",
    "    \n",
    "    bins.append(bin)\n",
    "\n",
    "for i, bin in enumerate(bins):\n",
    "    pos = sum(1 for g in bin if g.y.item() == 1)\n",
    "    neg = sum(1 for g in bin if g.y.item() == 0)\n",
    "    print(f\"Bin {i+1}: Positives = {pos}, Negatives = {neg}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d87fbedd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_graphs(train_losses, validation_losses, validation_accuracies, learning_rates):\n",
    "    # Plot Training Loss vs Validation Loss\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(range(1, len(train_losses) + 1), train_losses, label='Training Loss')\n",
    "    plt.plot(range(1, len(validation_losses) + 1), validation_losses, label='Validation Loss')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.title('Training Loss vs Validation Loss')\n",
    "    plt.legend()\n",
    "    plt.grid()\n",
    "    plt.show()\n",
    "\n",
    "    # Plot Validation Accuracy\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(range(1, len(validation_accuracies) + 1), validation_accuracies, label='Validation Accuracy', color='green')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.title('Validation Accuracy over Epochs')\n",
    "    plt.legend()\n",
    "    plt.grid()\n",
    "    plt.show()\n",
    "\n",
    "    # Plot Learning Rate\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(range(1, len(learning_rates) + 1), learning_rates, label='Learning Rates', color='green')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.title('Validation Accuracy over Epochs')\n",
    "    plt.legend()\n",
    "    plt.grid()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "85fa3d2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "def weighted_positive_loss(y_pred, y_true, lambda_weight=0.01):\n",
    "    # BCE Loss\n",
    "    bce_loss = F.binary_cross_entropy(y_pred, y_true)\n",
    "\n",
    "    # Additional Weighted Positive Term\n",
    "    positive_mask = (y_true == 1.0).float()\n",
    "    P = positive_mask.sum()\n",
    "\n",
    "    if P > 0:\n",
    "        wp_term = torch.sqrt(\n",
    "            torch.mean((torch.log(y_pred[positive_mask.bool()] + 1) - torch.log(y_true[positive_mask.bool()] + 1)) ** 2)\n",
    "        )\n",
    "    else:\n",
    "        wp_term = torch.tensor(0.0, device=y_pred.device)\n",
    "\n",
    "    total_loss = bce_loss + lambda_weight * wp_term\n",
    "    return total_loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b052f7f",
   "metadata": {
    "id": "ZusKMpZ-pLWI"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/alexhernandez/miniconda3/envs/cpp-ml/lib/python3.9/site-packages/torch_geometric/deprecation.py:26: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead\n",
      "  warnings.warn(out)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on bin 1/50\n",
      "Bin 1, Epoch 1/5000, Train Loss: 0.6920, Validation Loss: 0.6617,  ValAccuracy: 0.7825, LR: 0.000250\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Define paths for saving models\n",
    "save_dir = \"GATModels-5A_exp3\"\n",
    "os.makedirs(f\"{save_dir}/Models\", exist_ok=True)\n",
    "os.makedirs(f\"{save_dir}/Weights\", exist_ok=True)\n",
    "\n",
    "epochs = 5000\n",
    "batch_size = 256\n",
    "\n",
    "val_loader = DataLoader(validation_graphs, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "for i, bin in enumerate(bins, start=0):\n",
    "    model = GAT(in_channels=37, out_channels=32).to(device)\n",
    "    criterion = nn.BCELoss()  \n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.00025, weight_decay=1e-4)\n",
    "    #scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=10, threshold=1e-4)\n",
    "\n",
    "    train_loader = DataLoader(bin, batch_size=batch_size, shuffle=True)    \n",
    "\n",
    "    print(f\"Training on bin {i+1}/{len(bins)}\")\n",
    "\n",
    "    train_losses = []\n",
    "    learning_rates = []\n",
    "    validation_losses = []\n",
    "    validation_accuracies = []\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        epoch_loss, accuracy = train_model(model, train_loader, criterion, optimizer, device)\n",
    "        validation_loss, validation_accuracy, attention_data = validate_model(model, val_loader, criterion, device)\n",
    "        #scheduler.step(validation_loss)\n",
    "        \n",
    "        current_lr = optimizer.param_groups[0]['lr'] \n",
    "        train_losses.append(epoch_loss)\n",
    "        learning_rates.append(current_lr)\n",
    "        validation_losses.append(validation_loss)\n",
    "        validation_accuracies.append(validation_accuracy)   \n",
    "        if epoch % 500 == 0:\n",
    "            print(\n",
    "                f\"Bin {i+1}, Epoch {epoch+1}/{epochs}, \"\n",
    "                f\"Train Loss: {epoch_loss:.4f}, Validation Loss: {validation_loss:.4f},  \"\n",
    "                f\"ValAccuracy: {validation_accuracy:.4f}, \"\n",
    "                f\"LR: {current_lr:.6f}\"\n",
    "            )\n",
    "                \n",
    "    plot_graphs(train_losses, validation_losses, validation_accuracies, learning_rates)\n",
    "\n",
    "    #Save the trained model\n",
    "    model_path = os.path.join(save_dir, f\"Models/model_bin_{i+1}.pth\")\n",
    "    torch.save(model.state_dict(), model_path)\n",
    "    print(f\"Model for bin {i+1} saved to {model_path}\")\n",
    "\n",
    "    # Save attention weights\n",
    "    attn_path = os.path.join(save_dir, f\"Weights/attn_bin_{i+1}.pt\")\n",
    "    torch.save(attention_data, attn_path)\n",
    "    print(f\"Attention weights for bin {i+1} saved to {attn_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "419ac395-269a-4473-b4bb-41b51cfd8d4f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cpp-ml",
   "language": "python",
   "name": "cpp-ml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
