{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "742df4e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.loader import DataLoader\n",
    "from torch_geometric.nn import GATConv, global_mean_pool\n",
    "import glob\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "\n",
    "# Define GAT model for batched data\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import GATConv, global_mean_pool, global_add_pool, global_max_pool\n",
    "\n",
    "class GAT(nn.Module):\n",
    "    def __init__(self, in_channels, hidden_channels=32, out_channels=16, dropout_p=0.3):\n",
    "        super().__init__()\n",
    "        self.gat1 = GATConv(in_channels, hidden_channels, heads=1, concat=True, edge_dim=1)\n",
    "        self.norm1 = nn.BatchNorm1d(hidden_channels)\n",
    "        \n",
    "        self.gat2 = GATConv(hidden_channels, out_channels, heads=1, concat=True, edge_dim=1)\n",
    "        self.norm2 = nn.BatchNorm1d(out_channels)\n",
    "        \n",
    "        self.dropout = nn.Dropout(dropout_p)\n",
    "        self.pool = global_mean_pool\n",
    "\n",
    "        # MLP head\n",
    "        self.linear1 = nn.Linear(out_channels, 128)\n",
    "        self.linear2 = nn.Linear(128, 1)\n",
    "\n",
    "    def forward(self, x, edge_index, edge_attr, batch, return_attention=False): #only apply att weight for val\n",
    "        attn_weights = None\n",
    "\n",
    "        x = self.gat1(x, edge_index, edge_attr)\n",
    "        x = self.norm1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.dropout(x)\n",
    "\n",
    "        if return_attention:\n",
    "            x, attn_weights = self.gat2(x, edge_index, edge_attr, return_attention_weights=True)\n",
    "        else:\n",
    "            x = self.gat2(x, edge_index, edge_attr)\n",
    "\n",
    "        x = self.norm2(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.dropout(x)\n",
    "\n",
    "        x = self.pool(x, batch)\n",
    "        x = F.relu(self.linear1(x))\n",
    "        x = self.dropout(x)\n",
    "        x = self.linear2(x)\n",
    "\n",
    "        if return_attention:\n",
    "            return x.squeeze(1), attn_weights\n",
    "        return x.squeeze(1)\n",
    "\n",
    "\n",
    "def organize_graph_and_add_weight(file_path, label):\n",
    "    data = np.load(file_path, allow_pickle=True).item()\n",
    "    inverse_distance = data['inverse_distance']\n",
    "    encoded_matrix = data['encoded_matrix']\n",
    "\n",
    "    x = torch.tensor(encoded_matrix, dtype=torch.float32)\n",
    "    adj = torch.tensor(inverse_distance, dtype=torch.float32)\n",
    "\n",
    "    # Normalize adjacency (row-normalize)\n",
    "    adj = adj / (adj.sum(dim=1, keepdim=True) + 1e-8)\n",
    "\n",
    "    # Create edge_index and edge weights\n",
    "    edge_index = (adj > 0).nonzero(as_tuple=False).t()\n",
    "    edge_weight = adj[adj > 0]\n",
    "\n",
    "    y = torch.tensor([label], dtype=torch.float32)\n",
    "    \n",
    "    return Data(x=x, edge_index=edge_index, edge_attr=edge_weight, y=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "78c30293",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, dataloader, criterion, optimizer, device):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    total = 0\n",
    "    correct = 0\n",
    "\n",
    "    for batch in dataloader:\n",
    "        batch = batch.to(device)\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        outputs= model(batch.x, batch.edge_index, batch.edge_attr, batch.batch)\n",
    "        loss = criterion(outputs.view(-1), batch.y.view(-1))\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item() * batch.num_graphs\n",
    "        preds = torch.sigmoid(outputs) >= 0.5\n",
    "        correct += (preds == batch.y.view(-1).bool()).sum().item()\n",
    "        total += batch.num_graphs\n",
    "\n",
    "    epoch_loss = running_loss / total\n",
    "    accuracy = correct / total\n",
    "    return epoch_loss, accuracy\n",
    "\n",
    "\n",
    "def validate_model(model, dataloader, criterion, device):\n",
    "    model.eval()\n",
    "    running_loss = 0.0\n",
    "    total = 0\n",
    "    correct = 0\n",
    "    attention_data = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in dataloader:\n",
    "            batch = batch.to(device)\n",
    "\n",
    "            outputs, attn_weights = model(batch.x, batch.edge_index, batch.edge_attr, batch.batch, return_attention=True)\n",
    "            loss = criterion(outputs.view(-1), batch.y.view(-1))\n",
    "            running_loss += loss.item() * batch.num_graphs\n",
    "\n",
    "            preds = torch.sigmoid(outputs) >= 0.5\n",
    "            correct += (preds == batch.y.view(-1).bool()).sum().item()\n",
    "            total += batch.num_graphs\n",
    "\n",
    "            edge_idx, alpha = attn_weights\n",
    "            attention_data.append({\n",
    "                \"edge_index\": edge_idx.cpu(),\n",
    "                \"attention\": alpha.cpu(),\n",
    "                \"batch\": batch.batch.cpu()\n",
    "            })\n",
    "\n",
    "    validation_loss = running_loss / total\n",
    "    accuracy = correct / total\n",
    "    return validation_loss, accuracy, attention_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ccfc89c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In validation directory there are 77 positives and 277 fragments\n",
      "Bin 1: Positives = 385, Negatives = 385\n",
      "Bin 2: Positives = 385, Negatives = 385\n",
      "Bin 3: Positives = 385, Negatives = 385\n",
      "Bin 4: Positives = 385, Negatives = 385\n",
      "Bin 5: Positives = 385, Negatives = 385\n",
      "Bin 6: Positives = 385, Negatives = 385\n",
      "Bin 7: Positives = 385, Negatives = 385\n",
      "Bin 8: Positives = 385, Negatives = 385\n",
      "Bin 9: Positives = 385, Negatives = 385\n",
      "Bin 10: Positives = 385, Negatives = 385\n",
      "Bin 11: Positives = 385, Negatives = 385\n",
      "Bin 12: Positives = 385, Negatives = 385\n",
      "Bin 13: Positives = 385, Negatives = 385\n",
      "Bin 14: Positives = 385, Negatives = 385\n",
      "Bin 15: Positives = 385, Negatives = 385\n",
      "Bin 16: Positives = 385, Negatives = 385\n",
      "Bin 17: Positives = 385, Negatives = 385\n",
      "Bin 18: Positives = 385, Negatives = 385\n",
      "Bin 19: Positives = 385, Negatives = 385\n",
      "Bin 20: Positives = 385, Negatives = 385\n",
      "Bin 21: Positives = 385, Negatives = 385\n",
      "Bin 22: Positives = 385, Negatives = 385\n",
      "Bin 23: Positives = 385, Negatives = 385\n",
      "Bin 24: Positives = 385, Negatives = 385\n",
      "Bin 25: Positives = 385, Negatives = 385\n",
      "Bin 26: Positives = 385, Negatives = 385\n",
      "Bin 27: Positives = 385, Negatives = 385\n",
      "Bin 28: Positives = 385, Negatives = 385\n",
      "Bin 29: Positives = 385, Negatives = 385\n",
      "Bin 30: Positives = 385, Negatives = 385\n",
      "Bin 31: Positives = 385, Negatives = 385\n",
      "Bin 32: Positives = 385, Negatives = 385\n",
      "Bin 33: Positives = 385, Negatives = 385\n",
      "Bin 34: Positives = 385, Negatives = 385\n",
      "Bin 35: Positives = 385, Negatives = 385\n",
      "Bin 36: Positives = 385, Negatives = 385\n",
      "Bin 37: Positives = 385, Negatives = 385\n",
      "Bin 38: Positives = 385, Negatives = 385\n",
      "Bin 39: Positives = 385, Negatives = 385\n",
      "Bin 40: Positives = 385, Negatives = 385\n",
      "Bin 41: Positives = 385, Negatives = 385\n",
      "Bin 42: Positives = 385, Negatives = 385\n",
      "Bin 43: Positives = 385, Negatives = 385\n",
      "Bin 44: Positives = 385, Negatives = 385\n",
      "Bin 45: Positives = 385, Negatives = 385\n",
      "Bin 46: Positives = 385, Negatives = 385\n",
      "Bin 47: Positives = 385, Negatives = 385\n",
      "Bin 48: Positives = 385, Negatives = 385\n",
      "Bin 49: Positives = 385, Negatives = 385\n",
      "Bin 50: Positives = 385, Negatives = 385\n"
     ]
    }
   ],
   "source": [
    "# Create a dictionary with file names as keys and label + tensor grid as values\n",
    "positive_grids = glob.glob('../../../Data/SplitData/Cholesterol/cholesterol-separate-graphs-5A/PositiveWithoutSpies/*.npy')\n",
    "validation_grids = glob.glob('../../../Data/SplitData/Cholesterol/cholesterol-separate-graphs-5A/Validation_Set/*.npy')\n",
    "\n",
    "positive_graphs = []\n",
    "validation_graphs = []\n",
    "\n",
    "for file in positive_grids:\n",
    "    positive_graphs.append(organize_graph_and_add_weight(file, 1))\n",
    "\n",
    "positive_validation_count = 0\n",
    "unlabeled_validation_count = 0\n",
    "\n",
    "for file in validation_grids:\n",
    "    # Label as negative if \"-f1\" to \"-f5\" is in the filename\n",
    "    if any(f\"-f{i}\" in file for i in range(1, 6)):\n",
    "        label = 0\n",
    "        unlabeled_validation_count += 1\n",
    "        validation_graphs.append(organize_graph_and_add_weight(file, label))\n",
    "    else:\n",
    "        label = 1\n",
    "        positive_validation_count += 1\n",
    "        validation_graphs.append(organize_graph_and_add_weight(file, label))\n",
    "\n",
    "print(\"In validation directory there are\", positive_validation_count, \"positives and\", unlabeled_validation_count, \"fragments\")\n",
    "\n",
    "k = 50\n",
    "bins = []\n",
    "for i in range(1, k + 1):\n",
    "    bin = positive_graphs.copy()\n",
    "    subset_grid = glob.glob(f'../../../Data/SplitData/Cholesterol/cholesterol-separate-graphs-5A/k_subsets/subset_{i}/*.npy')  # Adjust path as needed\n",
    "    for file in subset_grid:\n",
    "        bin.append(organize_graph_and_add_weight(file, 0))\n",
    "    \n",
    "    bins.append(bin)\n",
    "\n",
    "for i, bin in enumerate(bins):\n",
    "    pos = sum(1 for g in bin if g.y.item() == 1)\n",
    "    neg = sum(1 for g in bin if g.y.item() == 0)\n",
    "    print(f\"Bin {i+1}: Positives = {pos}, Negatives = {neg}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d87fbedd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_graphs(train_losses, validation_losses, validation_accuracies, learning_rates):\n",
    "    # Plot Training Loss vs Validation Loss\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(range(1, len(train_losses) + 1), train_losses, label='Training Loss')\n",
    "    plt.plot(range(1, len(validation_losses) + 1), validation_losses, label='Validation Loss')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.title('Training Loss vs Validation Loss')\n",
    "    plt.legend()\n",
    "    plt.grid()\n",
    "    plt.show()\n",
    "\n",
    "    # Plot Validation Accuracy\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(range(1, len(validation_accuracies) + 1), validation_accuracies, label='Validation Accuracy', color='green')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.title('Validation Accuracy over Epochs')\n",
    "    plt.legend()\n",
    "    plt.grid()\n",
    "    plt.show()\n",
    "\n",
    "    # Plot Learning Rate\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(range(1, len(learning_rates) + 1), learning_rates, label='Learning Rates', color='green')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.title('Validation Accuracy over Epochs')\n",
    "    plt.legend()\n",
    "    plt.grid()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "85fa3d2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "def weighted_positive_loss(y_pred, y_true, lambda_weight=0.01):\n",
    "    # BCE Loss\n",
    "    bce_loss = F.binary_cross_entropy(y_pred, y_true)\n",
    "\n",
    "    # Additional Weighted Positive Term\n",
    "    positive_mask = (y_true == 1.0).float()\n",
    "    P = positive_mask.sum()\n",
    "\n",
    "    if P > 0:\n",
    "        wp_term = torch.sqrt(\n",
    "            torch.mean((torch.log(y_pred[positive_mask.bool()] + 1) - torch.log(y_true[positive_mask.bool()] + 1)) ** 2)\n",
    "        )\n",
    "    else:\n",
    "        wp_term = torch.tensor(0.0, device=y_pred.device)\n",
    "\n",
    "    total_loss = bce_loss + lambda_weight * wp_term\n",
    "    return total_loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6b052f7f",
   "metadata": {
    "id": "ZusKMpZ-pLWI"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on bin 1/50\n",
      "Bin 1, Epoch 1/1000, Train Loss: 0.6635, Validation Loss: 0.6878,  ValAccuracy: 0.7768, LR: 0.000001\n",
      "Bin 1, Epoch 11/1000, Train Loss: 0.6687, Validation Loss: 0.7066,  ValAccuracy: 0.3277, LR: 0.000001\n",
      "Bin 1, Epoch 21/1000, Train Loss: 0.6635, Validation Loss: 0.7093,  ValAccuracy: 0.3333, LR: 0.000001\n",
      "Bin 1, Epoch 31/1000, Train Loss: 0.6677, Validation Loss: 0.7090,  ValAccuracy: 0.3277, LR: 0.000001\n",
      "Bin 1, Epoch 41/1000, Train Loss: 0.6627, Validation Loss: 0.7075,  ValAccuracy: 0.3333, LR: 0.000001\n",
      "Bin 1, Epoch 51/1000, Train Loss: 0.6646, Validation Loss: 0.7045,  ValAccuracy: 0.3503, LR: 0.000001\n",
      "Bin 1, Epoch 61/1000, Train Loss: 0.6674, Validation Loss: 0.7055,  ValAccuracy: 0.3475, LR: 0.000001\n",
      "Bin 1, Epoch 71/1000, Train Loss: 0.6577, Validation Loss: 0.7081,  ValAccuracy: 0.3333, LR: 0.000001\n",
      "Bin 1, Epoch 81/1000, Train Loss: 0.6656, Validation Loss: 0.7097,  ValAccuracy: 0.3418, LR: 0.000001\n",
      "Bin 1, Epoch 91/1000, Train Loss: 0.6638, Validation Loss: 0.7073,  ValAccuracy: 0.3305, LR: 0.000001\n",
      "Bin 1, Epoch 101/1000, Train Loss: 0.6652, Validation Loss: 0.7034,  ValAccuracy: 0.3672, LR: 0.000001\n",
      "Bin 1, Epoch 111/1000, Train Loss: 0.6599, Validation Loss: 0.7057,  ValAccuracy: 0.3616, LR: 0.000001\n",
      "Bin 1, Epoch 121/1000, Train Loss: 0.6552, Validation Loss: 0.7099,  ValAccuracy: 0.3446, LR: 0.000001\n",
      "Bin 1, Epoch 131/1000, Train Loss: 0.6562, Validation Loss: 0.7043,  ValAccuracy: 0.3644, LR: 0.000001\n",
      "Bin 1, Epoch 141/1000, Train Loss: 0.6613, Validation Loss: 0.7085,  ValAccuracy: 0.3503, LR: 0.000001\n",
      "Bin 1, Epoch 151/1000, Train Loss: 0.6639, Validation Loss: 0.7112,  ValAccuracy: 0.3475, LR: 0.000001\n",
      "Bin 1, Epoch 161/1000, Train Loss: 0.6578, Validation Loss: 0.7106,  ValAccuracy: 0.3559, LR: 0.000001\n",
      "Bin 1, Epoch 171/1000, Train Loss: 0.6548, Validation Loss: 0.7048,  ValAccuracy: 0.3785, LR: 0.000001\n",
      "Bin 1, Epoch 181/1000, Train Loss: 0.6584, Validation Loss: 0.7068,  ValAccuracy: 0.3644, LR: 0.000001\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 25\u001b[0m\n\u001b[1;32m     22\u001b[0m train_losses, val_losses, val_accuracies, learning_rates \u001b[38;5;241m=\u001b[39m [], [], [], []\n\u001b[1;32m     24\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(epochs):\n\u001b[0;32m---> 25\u001b[0m     epoch_loss, accuracy \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     26\u001b[0m     validation_loss, validation_accuracy, attention_data \u001b[38;5;241m=\u001b[39m validate_model(model, val_loader, criterion, device)\n\u001b[1;32m     28\u001b[0m     current_lr \u001b[38;5;241m=\u001b[39m optimizer\u001b[38;5;241m.\u001b[39mparam_groups[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlr\u001b[39m\u001b[38;5;124m'\u001b[39m] \n",
      "Cell \u001b[0;32mIn[5], line 11\u001b[0m, in \u001b[0;36mtrain_model\u001b[0;34m(model, dataloader, criterion, optimizer, device)\u001b[0m\n\u001b[1;32m      8\u001b[0m batch \u001b[38;5;241m=\u001b[39m batch\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m      9\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m---> 11\u001b[0m outputs\u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43medge_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43medge_attr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbatch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     12\u001b[0m loss \u001b[38;5;241m=\u001b[39m criterion(outputs\u001b[38;5;241m.\u001b[39mview(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m), batch\u001b[38;5;241m.\u001b[39my\u001b[38;5;241m.\u001b[39mview(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m))\n\u001b[1;32m     13\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n",
      "File \u001b[0;32m~/miniconda3/envs/cpp-ml/lib/python3.9/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/cpp-ml/lib/python3.9/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "Cell \u001b[0;32mIn[4], line 41\u001b[0m, in \u001b[0;36mGAT.forward\u001b[0;34m(self, x, edge_index, edge_attr, batch, return_attention)\u001b[0m\n\u001b[1;32m     39\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnorm1(x)\n\u001b[1;32m     40\u001b[0m x \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mrelu(x)\n\u001b[0;32m---> 41\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdropout\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     43\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m return_attention:\n\u001b[1;32m     44\u001b[0m     x, attn_weights \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgat2(x, edge_index, edge_attr, return_attention_weights\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m~/miniconda3/envs/cpp-ml/lib/python3.9/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/cpp-ml/lib/python3.9/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Define paths for saving models\n",
    "save_dir = \"GATComplexModelsAndWeights-5A\"\n",
    "os.makedirs(f\"{save_dir}/Models\", exist_ok=True)\n",
    "os.makedirs(f\"{save_dir}/Weights\", exist_ok=True)\n",
    "\n",
    "epochs = 1000\n",
    "batch_size = 64\n",
    "\n",
    "val_loader = DataLoader(validation_graphs, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "for i, bin in enumerate(bins, start=0):\n",
    "    model = GAT(in_channels=37, out_channels=16).to(device)\n",
    "    criterion = nn.BCEWithLogitsLoss()  \n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.000001, weight_decay=1e-4)\n",
    "\n",
    "    train_loader = DataLoader(bin, batch_size=batch_size, shuffle=True)    \n",
    "\n",
    "    print(f\"Training on bin {i+1}/{len(bins)}\")\n",
    "\n",
    "    train_losses, val_losses, val_accuracies, learning_rates = [], [], [], []\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        epoch_loss, accuracy = train_model(model, train_loader, criterion, optimizer, device)\n",
    "        validation_loss, validation_accuracy, attention_data = validate_model(model, val_loader, criterion, device)\n",
    "        \n",
    "        current_lr = optimizer.param_groups[0]['lr'] \n",
    "        train_losses.append(epoch_loss)\n",
    "        learning_rates.append(current_lr)\n",
    "        val_losses.append(validation_loss)\n",
    "        val_accuracies.append(validation_accuracy)   \n",
    "\n",
    "        if epoch % 10 == 0:\n",
    "            print(\n",
    "                f\"Bin {i+1}, Epoch {epoch+1}/{epochs}, \"\n",
    "                f\"Train Loss: {epoch_loss:.4f}, Validation Loss: {validation_loss:.4f},  \"\n",
    "                f\"ValAccuracy: {validation_accuracy:.4f}, \"\n",
    "                f\"LR: {current_lr:.6f}\"\n",
    "            )\n",
    "                \n",
    "    plot_graphs(train_losses, val_losses, val_accuracies, learning_rates)\n",
    "\n",
    "    #Save the trained model\n",
    "    model_path = os.path.join(save_dir, f\"Models/model_bin_{i+1}.pth\")\n",
    "    torch.save(model.state_dict(), model_path)\n",
    "    print(f\"Model for bin {i+1} saved to {model_path}\")\n",
    "\n",
    "    # Save attention weights\n",
    "    attn_path = os.path.join(save_dir, f\"Weights/attn_bin_{i+1}.pt\")\n",
    "    torch.save(attention_data, attn_path)\n",
    "    print(f\"Attention weights for bin {i+1} saved to {attn_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "419ac395-269a-4473-b4bb-41b51cfd8d4f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cpp-ml",
   "language": "python",
   "name": "cpp-ml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
