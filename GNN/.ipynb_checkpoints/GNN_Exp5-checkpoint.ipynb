{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "48a6205f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.optim as optim\n",
    "import glob\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Define the 2D CNN model in PyTorch\n",
    "class CNN2D(nn.Module):\n",
    "    def __init__(self, input_channels):\n",
    "        super(CNN2D, self).__init__()\n",
    "        self.conv1 = nn.Sequential(\n",
    "            nn.Conv2d(input_channels, 32, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        self.pool1 = nn.MaxPool2d(2, 2)\n",
    "        \n",
    "        self.conv2 = nn.Sequential(\n",
    "            nn.Conv2d(32, 64, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        self.pool2 = nn.MaxPool2d(2, 2)\n",
    "        \n",
    "        self.conv3 = nn.Sequential(\n",
    "            nn.Conv2d(64, 128, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        self.pool3 = nn.MaxPool2d(2, 2)\n",
    "        \n",
    "        self.flatten = nn.Flatten()\n",
    "        self.fc1 = nn.Linear(128 * 4 * 18, 128)  # Adjust based on input size\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "        self.fc2 = nn.Linear(128, 1)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.pool1(x)\n",
    "        \n",
    "        x = self.conv2(x)\n",
    "        x = self.pool2(x)\n",
    "        \n",
    "        x = self.conv3(x)\n",
    "        x = self.pool3(x)\n",
    "        \n",
    "        x = self.flatten(x)\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc2(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "22279bce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training method for PyTorch\n",
    "def train_model(model, dataloader, criterion, optimizer, device):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    total = 0\n",
    "    correct = 0\n",
    "\n",
    "    for inputs, labels in dataloader:\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs).squeeze(1)\n",
    "        loss = criterion(outputs, labels.squeeze(1))\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item() * inputs.size(0)\n",
    "        preds = torch.sigmoid(outputs) >= 0.5\n",
    "        correct += (preds == labels.squeeze(1).bool()).sum().item()\n",
    "        total += labels.size(0)\n",
    "\n",
    "    epoch_loss = running_loss / total\n",
    "    accuracy = correct / total\n",
    "    return epoch_loss, accuracy\n",
    "\n",
    "# Validation function\n",
    "def validate_model(model, dataloader, criterion, device):\n",
    "    model.eval()  # Set model to evaluation mode\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    with torch.no_grad():  # Disable gradient calculation\n",
    "        for inputs, labels in dataloader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            \n",
    "            # Forward pass\n",
    "            outputs = model(inputs).squeeze(1)\n",
    "            loss = criterion(outputs, labels.squeeze(1))\n",
    "            running_loss += loss.item() * inputs.size(0)\n",
    "            \n",
    "            # Compute accuracy\n",
    "            preds = torch.sigmoid(outputs) >= 0.5\n",
    "            correct += (preds == labels.squeeze(1).bool()).sum().item()\n",
    "            total += labels.size(0)\n",
    "    \n",
    "    validation_loss = running_loss / total\n",
    "    accuracy = correct / total\n",
    "    return validation_loss, accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "17de107b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GridDataset(Dataset):\n",
    "    def __init__(self, data_dict):\n",
    "        self.data = list(data_dict.values())\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        sample = self.data[idx]\n",
    "        grid = sample['grid_tensor']\n",
    "        label = torch.tensor(sample['label'], dtype=torch.float32)\n",
    "        return grid, label.unsqueeze(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ccfc89c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "385 is length of positive\n",
      "In validation directory there are 77 positives and 277 fragments\n",
      "354 is length of validation grids\n",
      "0 is length of subset grid\n",
      "0 is length of subset grid\n",
      "0 is length of subset grid\n",
      "0 is length of subset grid\n",
      "0 is length of subset grid\n",
      "0 is length of subset grid\n",
      "0 is length of subset grid\n",
      "0 is length of subset grid\n",
      "0 is length of subset grid\n",
      "0 is length of subset grid\n",
      "0 is length of subset grid\n",
      "0 is length of subset grid\n",
      "0 is length of subset grid\n",
      "0 is length of subset grid\n",
      "0 is length of subset grid\n",
      "0 is length of subset grid\n",
      "0 is length of subset grid\n",
      "0 is length of subset grid\n",
      "0 is length of subset grid\n",
      "0 is length of subset grid\n",
      "0 is length of subset grid\n",
      "0 is length of subset grid\n",
      "0 is length of subset grid\n",
      "0 is length of subset grid\n",
      "0 is length of subset grid\n",
      "0 is length of subset grid\n",
      "0 is length of subset grid\n",
      "0 is length of subset grid\n",
      "0 is length of subset grid\n",
      "0 is length of subset grid\n",
      "0 is length of subset grid\n",
      "0 is length of subset grid\n",
      "0 is length of subset grid\n",
      "0 is length of subset grid\n",
      "0 is length of subset grid\n",
      "0 is length of subset grid\n",
      "0 is length of subset grid\n",
      "0 is length of subset grid\n",
      "0 is length of subset grid\n",
      "0 is length of subset grid\n",
      "0 is length of subset grid\n",
      "0 is length of subset grid\n",
      "0 is length of subset grid\n",
      "0 is length of subset grid\n",
      "0 is length of subset grid\n",
      "0 is length of subset grid\n",
      "0 is length of subset grid\n",
      "0 is length of subset grid\n",
      "0 is length of subset grid\n",
      "0 is length of subset grid\n"
     ]
    }
   ],
   "source": [
    "# Create a dictionary with file names as keys and label + tensor grid as values\n",
    "positive_grids = glob.glob('../../../Data/SplitData/Cholesterol/cholesterol-graph-5A_exp2/PositiveWithoutSpies/*.npy')\n",
    "validation_grids = glob.glob('../../../Data/SplitData/Cholesterol/cholesterol-graph-5A_exp2/Validation_Set/*.npy')\n",
    "file_data = {} # format is filename as key, label and grid tensor are values\n",
    "\n",
    "for file in positive_grids:\n",
    "    # Load the numpy array and convert it to a PyTorch tensor\n",
    "    grid = np.load(file)\n",
    "    grid_tensor = torch.tensor(grid, dtype=torch.float32).unsqueeze(0)  # Adds channel dimension\n",
    "    file_data[file] = {'label': 1, 'grid_tensor': grid_tensor}\n",
    "positive_grids = file_data\n",
    "print(len(positive_grids), \"is length of positive\")\n",
    "\n",
    "file_data = {} # format is filename as key, label and grid tensor are values\n",
    "\n",
    "positive_validation_count = 0\n",
    "unlabeled_validation_count = 0\n",
    "\n",
    "for file in validation_grids:\n",
    "    # Load the numpy array and convert it to a PyTorch tensor\n",
    "    grid = np.load(file)\n",
    "    grid_tensor = torch.tensor(grid, dtype=torch.float32).unsqueeze(0)  # Adds channel dimension\n",
    "    # Label as negative if \"-f1\" to \"-f5\" is in the filename\n",
    "    if any(f\"-f{i}\" in file for i in range(1, 6)):\n",
    "        label = 0\n",
    "        unlabeled_validation_count += 1\n",
    "    else:\n",
    "        label = 1\n",
    "        positive_validation_count += 1\n",
    "\n",
    "    file_data[file] = {'label': label, 'grid_tensor': grid_tensor}\n",
    "print(\"In validation directory there are\", positive_validation_count, \"positives and\", unlabeled_validation_count, \"fragments\")\n",
    "validation_grids = file_data\n",
    "print(len(validation_grids), \"is length of validation grids\")\n",
    "\n",
    "\n",
    "file_data = {} # format is filename as key, label and grid tensor are values\n",
    "\n",
    "k = 50\n",
    "subset_grids = []\n",
    "for i in range(1, k + 1):\n",
    "    file_data = {}\n",
    "    subset_grid = glob.glob(f'../../../Data/SplitData/Cholesterol/cholesterol-graph-5A_exp2/k_subsets/subset_{i}/*.npy')  # Adjust path as needed\n",
    "    for file in subset_grid:\n",
    "        # Load the numpy array and convert it to a PyTorch tensor\n",
    "        grid = np.load(file)\n",
    "        grid_tensor = torch.tensor(grid, dtype=torch.float32).unsqueeze(0)  # Adds channel dimension\n",
    "        file_data[file] = {'label': 0, 'grid_tensor': grid_tensor} # 0 means unlabeled\n",
    "    subset_grid = file_data\n",
    "    subset_grids.append(subset_grid)\n",
    "    print(len(subset_grid), \"is length of subset grid\")\n",
    "\n",
    "bins = []\n",
    "for subset_grid in subset_grids:\n",
    "    bin = {**positive_grids, **subset_grid} # merged\n",
    "    bins.append(bin)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d87fbedd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_graphs(train_losses, validation_losses, validation_accuracies, learning_rates):\n",
    "    # Plot Training Loss vs Validation Loss\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(range(1, len(train_losses) + 1), train_losses, label='Training Loss')\n",
    "    plt.plot(range(1, len(validation_losses) + 1), validation_losses, label='Validation Loss')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.title('Training Loss vs Validation Loss')\n",
    "    plt.legend()\n",
    "    plt.grid()\n",
    "    plt.show()\n",
    "\n",
    "    # Plot Validation Accuracy\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(range(1, len(validation_accuracies) + 1), validation_accuracies, label='Validation Accuracy', color='green')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.title('Validation Accuracy over Epochs')\n",
    "    plt.legend()\n",
    "    plt.grid()\n",
    "    plt.show()\n",
    "\n",
    "    # Plot Learning Rate\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(range(1, len(learning_rates) + 1), learning_rates, label='Learning Rates', color='green')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.title('Validation Accuracy over Epochs')\n",
    "    plt.legend()\n",
    "    plt.grid()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "85fa3d2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "def weighted_positive_loss(y_pred, y_true, lambda_weight=0.01):\n",
    "    # BCE Loss\n",
    "    bce_loss = F.binary_cross_entropy(y_pred, y_true)\n",
    "\n",
    "    # Additional Weighted Positive Term\n",
    "    positive_mask = (y_true == 1.0).float()\n",
    "    P = positive_mask.sum()\n",
    "\n",
    "    if P > 0:\n",
    "        wp_term = torch.sqrt(\n",
    "            torch.mean((torch.log(y_pred[positive_mask.bool()] + 1) - torch.log(y_true[positive_mask.bool()] + 1)) ** 2)\n",
    "        )\n",
    "    else:\n",
    "        wp_term = torch.tensor(0.0, device=y_pred.device)\n",
    "\n",
    "    total_loss = bce_loss + lambda_weight * wp_term\n",
    "    return total_loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "10ab4cae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 4 GPUs\n",
      "Training on bin 1/50\n",
      "Bin 1, Epoch 1/2000, Train Loss: 629.5310, Validation Loss: 122.4812,  Accuracy: 0.3974, LR: 0.000001\n",
      "Bin 1, Epoch 101/2000, Train Loss: 619.4989, Validation Loss: 122.4556,  Accuracy: 0.9896, LR: 0.000001\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 42\u001b[0m\n\u001b[1;32m     39\u001b[0m best_model_state \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     41\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(epochs):\n\u001b[0;32m---> 42\u001b[0m     epoch_loss, accuracy \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdataloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     43\u001b[0m     validation_loss, validation_accuracy \u001b[38;5;241m=\u001b[39m validate_model(model, validation_dataloader, criterion, device)\n\u001b[1;32m     44\u001b[0m     current_lr \u001b[38;5;241m=\u001b[39m optimizer\u001b[38;5;241m.\u001b[39mparam_groups[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlr\u001b[39m\u001b[38;5;124m'\u001b[39m] \n",
      "Cell \u001b[0;32mIn[2], line 12\u001b[0m, in \u001b[0;36mtrain_model\u001b[0;34m(model, dataloader, criterion, optimizer, device)\u001b[0m\n\u001b[1;32m     10\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m     11\u001b[0m outputs \u001b[38;5;241m=\u001b[39m model(inputs)\u001b[38;5;241m.\u001b[39msqueeze(\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m---> 12\u001b[0m loss \u001b[38;5;241m=\u001b[39m criterion(outputs, \u001b[43mlabels\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msqueeze\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m)\n\u001b[1;32m     13\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[1;32m     14\u001b[0m torch\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39mclip_grad_norm_(model\u001b[38;5;241m.\u001b[39mparameters(), max_norm\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1.0\u001b[39m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Set device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Initialize the model\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "\n",
    "# Define paths for saving models\n",
    "save_dir = \"GNN-5A_Exp2\"\n",
    "os.makedirs(save_dir, exist_ok=True)\n",
    "\n",
    "# Training loop\n",
    "epochs = 2000\n",
    "batch_size = 128\n",
    "\n",
    "# keep 10 positives and 10 negatives for validation data\n",
    "validation_dataset = GridDataset(validation_grids)\n",
    "validation_dataloader = DataLoader(validation_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "for i in range(0, len(bins)):\n",
    "    model = CNN2D(input_channels=1).to(device)\n",
    "    if torch.cuda.device_count() > 1:\n",
    "        print(f\"Using {torch.cuda.device_count()} GPUs\")\n",
    "        model = nn.DataParallel(model)\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.000001, weight_decay=1e-4) \n",
    "    scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=5000, eta_min=1e-10)\n",
    "\n",
    "    print(f\"Training on bin {i+1}/{len(bins)}\")\n",
    "    dataset = GridDataset(bins[i])\n",
    "    dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "    train_losses = []\n",
    "    learning_rates = []\n",
    "    validation_losses = []\n",
    "    validation_accuracies = []\n",
    "\n",
    "    best_val_loss = float(\"inf\")\n",
    "    best_model_state = None\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        epoch_loss, accuracy = train_model(model, dataloader, criterion, optimizer, device)\n",
    "        validation_loss, validation_accuracy = validate_model(model, validation_dataloader, criterion, device)\n",
    "        current_lr = optimizer.param_groups[0]['lr'] \n",
    "        train_losses.append(epoch_loss)\n",
    "        learning_rates.append(current_lr)\n",
    "        validation_losses.append(validation_loss)\n",
    "        validation_accuracies.append(validation_accuracy)   \n",
    "        if epoch % 100 == 0:\n",
    "            print(\n",
    "                f\"Bin {i+1}, Epoch {epoch+1}/{epochs}, \"\n",
    "                f\"Train Loss: {epoch_loss:.4f}, Validation Loss: {validation_loss:.4f},  \"\n",
    "                f\"Accuracy: {accuracy:.4f}, \"\n",
    "                f\"LR: {current_lr:.6f}\"\n",
    "            )\n",
    "\n",
    "        if validation_loss < best_val_loss:\n",
    "            best_val_loss = validation_loss\n",
    "            best_model_state = model.state_dict()\n",
    "        scheduler.step()\n",
    "\n",
    "    plot_graphs(train_losses, validation_losses, validation_accuracies, learning_rates)\n",
    "    \n",
    "    #Save the trained model\n",
    "    model_path = os.path.join(save_dir, f\"model_bin_{i+1}.pth\")\n",
    "    torch.save(model.state_dict(), model_path)\n",
    "    print(f\"Model for bin {i+1} saved to {model_path}\")\n",
    "\n",
    "\n",
    "print(\"Training complete.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3aacb46a-8436-4e23-aab0-8c173baceeab",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cpp-ml",
   "language": "python",
   "name": "cpp-ml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
