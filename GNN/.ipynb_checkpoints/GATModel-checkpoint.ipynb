{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "742df4e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.loader import DataLoader\n",
    "from torch_geometric.nn import GATConv, global_mean_pool\n",
    "from torch_geometric.data import DataLoader\n",
    "import glob\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "\n",
    "# Define GAT model for batched data\n",
    "class GAT(torch.nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, dropout_p=0.5):\n",
    "        super().__init__()\n",
    "        self.gat = GATConv(in_channels, out_channels, heads=1, concat=True, edge_dim=1)\n",
    "        self.pool = global_mean_pool  # Can also use global_max_pool or global_add_pool\n",
    "        self.dropout = nn.Dropout(p=dropout_p)\n",
    "        self.linear = torch.nn.Linear(out_channels, 1)\n",
    "        self.activation = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x, edge_index, edge_attr, batch):\n",
    "        out, attn_weights = self.gat(x, edge_index, edge_attr, return_attention_weights=True)\n",
    "        out = self.dropout(out)\n",
    "        out = self.pool(out, batch)  # Pool over nodes in each graph\n",
    "        out = self.dropout(out) \n",
    "        out = self.linear(out)\n",
    "        out = self.dropout(out)\n",
    "        out = self.activation(out)\n",
    "        return out, attn_weights\n",
    "\n",
    "def organize_graph_and_add_weight(file_path, label):\n",
    "    data = np.load(file_path, allow_pickle=True).item()\n",
    "    inverse_distance = data['inverse_distance']\n",
    "    encoded_matrix = data['encoded_matrix']\n",
    "\n",
    "    x = torch.tensor(encoded_matrix, dtype=torch.float32)\n",
    "    adj = torch.tensor(inverse_distance, dtype=torch.float32)\n",
    "\n",
    "    # Normalize adjacency (row-normalize)\n",
    "    adj = adj / (adj.sum(dim=1, keepdim=True) + 1e-8)\n",
    "\n",
    "    # Create edge_index and edge weights\n",
    "    edge_index = (adj > 0).nonzero(as_tuple=False).t()\n",
    "    edge_weight = adj[adj > 0]\n",
    "\n",
    "    y = torch.tensor([label], dtype=torch.float32)\n",
    "    \n",
    "    return Data(x=x, edge_index=edge_index, edge_attr=edge_weight, y=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "78c30293",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, dataloader, criterion, optimizer, device):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    total = 0\n",
    "    correct = 0\n",
    "\n",
    "    for batch in dataloader:\n",
    "        batch = batch.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs, _ = model(batch.x, batch.edge_index, batch.edge_attr, batch.batch)\n",
    "        outputs = outputs.view(-1)  # shape: [batch_size]\n",
    "        loss = criterion(outputs, batch.y.view(-1))\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item() * batch.num_graphs\n",
    "        preds = outputs >= 0.5\n",
    "        correct += (preds == batch.y.view(-1).bool()).sum().item()\n",
    "        total += batch.num_graphs\n",
    "\n",
    "    epoch_loss = running_loss / total\n",
    "    accuracy = correct / total\n",
    "    return epoch_loss, accuracy\n",
    "\n",
    "\n",
    "def validate_model(model, dataloader, criterion, device):\n",
    "    model.eval()\n",
    "    running_loss = 0.0\n",
    "    total = 0\n",
    "    correct = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in dataloader:\n",
    "            batch = batch.to(device)\n",
    "            outputs, _ = model(batch.x, batch.edge_index, batch.edge_attr, batch.batch)\n",
    "            outputs = outputs.view(-1)\n",
    "            loss = criterion(outputs, batch.y.view(-1))\n",
    "            running_loss += loss.item() * batch.num_graphs\n",
    "            preds = outputs >= 0.5\n",
    "            correct += (preds == batch.y.view(-1).bool()).sum().item()\n",
    "            total += batch.num_graphs\n",
    "\n",
    "    validation_loss = running_loss / total\n",
    "    accuracy = correct / total\n",
    "    return validation_loss, accuracy, _\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ccfc89c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In validation directory there are 77 positives and 277 fragments\n",
      "Bin 1: Positives = 385, Negatives = 385\n",
      "Bin 2: Positives = 385, Negatives = 385\n",
      "Bin 3: Positives = 385, Negatives = 385\n",
      "Bin 4: Positives = 385, Negatives = 385\n",
      "Bin 5: Positives = 385, Negatives = 385\n",
      "Bin 6: Positives = 385, Negatives = 385\n",
      "Bin 7: Positives = 385, Negatives = 385\n",
      "Bin 8: Positives = 385, Negatives = 385\n",
      "Bin 9: Positives = 385, Negatives = 385\n",
      "Bin 10: Positives = 385, Negatives = 385\n",
      "Bin 11: Positives = 385, Negatives = 385\n",
      "Bin 12: Positives = 385, Negatives = 385\n",
      "Bin 13: Positives = 385, Negatives = 385\n",
      "Bin 14: Positives = 385, Negatives = 385\n",
      "Bin 15: Positives = 385, Negatives = 385\n",
      "Bin 16: Positives = 385, Negatives = 385\n",
      "Bin 17: Positives = 385, Negatives = 385\n",
      "Bin 18: Positives = 385, Negatives = 385\n",
      "Bin 19: Positives = 385, Negatives = 385\n",
      "Bin 20: Positives = 385, Negatives = 385\n",
      "Bin 21: Positives = 385, Negatives = 385\n",
      "Bin 22: Positives = 385, Negatives = 385\n",
      "Bin 23: Positives = 385, Negatives = 385\n",
      "Bin 24: Positives = 385, Negatives = 385\n",
      "Bin 25: Positives = 385, Negatives = 385\n",
      "Bin 26: Positives = 385, Negatives = 385\n",
      "Bin 27: Positives = 385, Negatives = 385\n",
      "Bin 28: Positives = 385, Negatives = 385\n",
      "Bin 29: Positives = 385, Negatives = 385\n",
      "Bin 30: Positives = 385, Negatives = 385\n",
      "Bin 31: Positives = 385, Negatives = 385\n",
      "Bin 32: Positives = 385, Negatives = 385\n",
      "Bin 33: Positives = 385, Negatives = 385\n",
      "Bin 34: Positives = 385, Negatives = 385\n",
      "Bin 35: Positives = 385, Negatives = 385\n",
      "Bin 36: Positives = 385, Negatives = 385\n",
      "Bin 37: Positives = 385, Negatives = 385\n",
      "Bin 38: Positives = 385, Negatives = 385\n",
      "Bin 39: Positives = 385, Negatives = 385\n",
      "Bin 40: Positives = 385, Negatives = 385\n",
      "Bin 41: Positives = 385, Negatives = 385\n",
      "Bin 42: Positives = 385, Negatives = 385\n",
      "Bin 43: Positives = 385, Negatives = 385\n",
      "Bin 44: Positives = 385, Negatives = 385\n",
      "Bin 45: Positives = 385, Negatives = 385\n",
      "Bin 46: Positives = 385, Negatives = 385\n",
      "Bin 47: Positives = 385, Negatives = 385\n",
      "Bin 48: Positives = 385, Negatives = 385\n",
      "Bin 49: Positives = 385, Negatives = 385\n",
      "Bin 50: Positives = 385, Negatives = 385\n"
     ]
    }
   ],
   "source": [
    "# Create a dictionary with file names as keys and label + tensor grid as values\n",
    "positive_grids = glob.glob('../../../Data/SplitData/Cholesterol/cholesterol-separate-graphs-5A/PositiveWithoutSpies/*.npy')\n",
    "validation_grids = glob.glob('../../../Data/SplitData/Cholesterol/cholesterol-separate-graphs-5A/Validation_Set/*.npy')\n",
    "\n",
    "positive_graphs = []\n",
    "validation_graphs = []\n",
    "\n",
    "for file in positive_grids:\n",
    "    positive_graphs.append(organize_graph_and_add_weight(file, 1))\n",
    "\n",
    "positive_validation_count = 0\n",
    "unlabeled_validation_count = 0\n",
    "\n",
    "for file in validation_grids:\n",
    "    # Label as negative if \"-f1\" to \"-f5\" is in the filename\n",
    "    if any(f\"-f{i}\" in file for i in range(1, 6)):\n",
    "        label = 0\n",
    "        unlabeled_validation_count += 1\n",
    "        validation_graphs.append(organize_graph_and_add_weight(file, label))\n",
    "    else:\n",
    "        label = 1\n",
    "        positive_validation_count += 1\n",
    "        validation_graphs.append(organize_graph_and_add_weight(file, label))\n",
    "\n",
    "print(\"In validation directory there are\", positive_validation_count, \"positives and\", unlabeled_validation_count, \"fragments\")\n",
    "\n",
    "k = 50\n",
    "bins = []\n",
    "for i in range(1, k + 1):\n",
    "    bin = positive_graphs.copy()\n",
    "    subset_grid = glob.glob(f'../../../Data/SplitData/Cholesterol/cholesterol-separate-graphs-5A/k_subsets/subset_{i}/*.npy')  # Adjust path as needed\n",
    "    for file in subset_grid:\n",
    "        bin.append(organize_graph_and_add_weight(file, 0))\n",
    "    \n",
    "    bins.append(bin)\n",
    "\n",
    "for i, bin in enumerate(bins):\n",
    "    pos = sum(1 for g in bin if g.y.item() == 1)\n",
    "    neg = sum(1 for g in bin if g.y.item() == 0)\n",
    "    print(f\"Bin {i+1}: Positives = {pos}, Negatives = {neg}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d87fbedd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_graphs(train_losses, validation_losses, validation_accuracies, learning_rates):\n",
    "    # Plot Training Loss vs Validation Loss\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(range(1, len(train_losses) + 1), train_losses, label='Training Loss')\n",
    "    plt.plot(range(1, len(validation_losses) + 1), validation_losses, label='Validation Loss')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.title('Training Loss vs Validation Loss')\n",
    "    plt.legend()\n",
    "    plt.grid()\n",
    "    plt.show()\n",
    "\n",
    "    # Plot Validation Accuracy\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(range(1, len(validation_accuracies) + 1), validation_accuracies, label='Validation Accuracy', color='green')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.title('Validation Accuracy over Epochs')\n",
    "    plt.legend()\n",
    "    plt.grid()\n",
    "    plt.show()\n",
    "\n",
    "    # Plot Learning Rate\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(range(1, len(learning_rates) + 1), learning_rates, label='Learning Rates', color='green')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.title('Validation Accuracy over Epochs')\n",
    "    plt.legend()\n",
    "    plt.grid()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "85fa3d2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "def weighted_positive_loss(y_pred, y_true, lambda_weight=0.01):\n",
    "    # BCE Loss\n",
    "    bce_loss = F.binary_cross_entropy(y_pred, y_true)\n",
    "\n",
    "    # Additional Weighted Positive Term\n",
    "    positive_mask = (y_true == 1.0).float()\n",
    "    P = positive_mask.sum()\n",
    "\n",
    "    if P > 0:\n",
    "        wp_term = torch.sqrt(\n",
    "            torch.mean((torch.log(y_pred[positive_mask.bool()] + 1) - torch.log(y_true[positive_mask.bool()] + 1)) ** 2)\n",
    "        )\n",
    "    else:\n",
    "        wp_term = torch.tensor(0.0, device=y_pred.device)\n",
    "\n",
    "    total_loss = bce_loss + lambda_weight * wp_term\n",
    "    return total_loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6b052f7f",
   "metadata": {
    "id": "ZusKMpZ-pLWI"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on bin 1/50\n",
      "Bin 1, Epoch 1/600, Train Loss: 0.6982, Validation Loss: 0.7288,  ValAccuracy: 0.2175, LR: 0.000001\n",
      "Bin 1, Epoch 11/600, Train Loss: 0.6993, Validation Loss: 0.7287,  ValAccuracy: 0.2175, LR: 0.000001\n",
      "Bin 1, Epoch 21/600, Train Loss: 0.6980, Validation Loss: 0.7287,  ValAccuracy: 0.2175, LR: 0.000001\n",
      "Bin 1, Epoch 31/600, Train Loss: 0.7003, Validation Loss: 0.7287,  ValAccuracy: 0.2175, LR: 0.000001\n",
      "Bin 1, Epoch 41/600, Train Loss: 0.6958, Validation Loss: 0.7287,  ValAccuracy: 0.2175, LR: 0.000001\n",
      "Bin 1, Epoch 51/600, Train Loss: 0.7041, Validation Loss: 0.7287,  ValAccuracy: 0.2175, LR: 0.000001\n",
      "Bin 1, Epoch 61/600, Train Loss: 0.6961, Validation Loss: 0.7287,  ValAccuracy: 0.2175, LR: 0.000001\n",
      "Bin 1, Epoch 71/600, Train Loss: 0.7016, Validation Loss: 0.7287,  ValAccuracy: 0.2175, LR: 0.000001\n",
      "Bin 1, Epoch 81/600, Train Loss: 0.6967, Validation Loss: 0.7287,  ValAccuracy: 0.2175, LR: 0.000001\n",
      "Bin 1, Epoch 91/600, Train Loss: 0.6992, Validation Loss: 0.7286,  ValAccuracy: 0.2175, LR: 0.000001\n",
      "Bin 1, Epoch 101/600, Train Loss: 0.6979, Validation Loss: 0.7286,  ValAccuracy: 0.2175, LR: 0.000001\n",
      "Bin 1, Epoch 111/600, Train Loss: 0.6982, Validation Loss: 0.7286,  ValAccuracy: 0.2175, LR: 0.000001\n",
      "Bin 1, Epoch 121/600, Train Loss: 0.6951, Validation Loss: 0.7286,  ValAccuracy: 0.2175, LR: 0.000001\n",
      "Bin 1, Epoch 131/600, Train Loss: 0.6969, Validation Loss: 0.7286,  ValAccuracy: 0.2175, LR: 0.000001\n",
      "Bin 1, Epoch 141/600, Train Loss: 0.6975, Validation Loss: 0.7286,  ValAccuracy: 0.2175, LR: 0.000001\n",
      "Bin 1, Epoch 151/600, Train Loss: 0.6990, Validation Loss: 0.7286,  ValAccuracy: 0.2175, LR: 0.000001\n",
      "Bin 1, Epoch 161/600, Train Loss: 0.7007, Validation Loss: 0.7286,  ValAccuracy: 0.2175, LR: 0.000001\n",
      "Bin 1, Epoch 171/600, Train Loss: 0.7014, Validation Loss: 0.7286,  ValAccuracy: 0.2175, LR: 0.000001\n",
      "Bin 1, Epoch 181/600, Train Loss: 0.6948, Validation Loss: 0.7285,  ValAccuracy: 0.2175, LR: 0.000001\n",
      "Bin 1, Epoch 191/600, Train Loss: 0.6979, Validation Loss: 0.7285,  ValAccuracy: 0.2175, LR: 0.000001\n",
      "Bin 1, Epoch 201/600, Train Loss: 0.6979, Validation Loss: 0.7285,  ValAccuracy: 0.2175, LR: 0.000001\n",
      "Bin 1, Epoch 211/600, Train Loss: 0.6985, Validation Loss: 0.7285,  ValAccuracy: 0.2175, LR: 0.000001\n",
      "Bin 1, Epoch 221/600, Train Loss: 0.6999, Validation Loss: 0.7285,  ValAccuracy: 0.2175, LR: 0.000001\n",
      "Bin 1, Epoch 231/600, Train Loss: 0.6991, Validation Loss: 0.7285,  ValAccuracy: 0.2175, LR: 0.000001\n",
      "Bin 1, Epoch 241/600, Train Loss: 0.6981, Validation Loss: 0.7285,  ValAccuracy: 0.2175, LR: 0.000001\n",
      "Bin 1, Epoch 251/600, Train Loss: 0.7004, Validation Loss: 0.7285,  ValAccuracy: 0.2175, LR: 0.000001\n",
      "Bin 1, Epoch 261/600, Train Loss: 0.7003, Validation Loss: 0.7285,  ValAccuracy: 0.2175, LR: 0.000001\n",
      "Bin 1, Epoch 271/600, Train Loss: 0.6946, Validation Loss: 0.7285,  ValAccuracy: 0.2175, LR: 0.000001\n",
      "Bin 1, Epoch 281/600, Train Loss: 0.6999, Validation Loss: 0.7284,  ValAccuracy: 0.2175, LR: 0.000001\n",
      "Bin 1, Epoch 291/600, Train Loss: 0.6979, Validation Loss: 0.7284,  ValAccuracy: 0.2175, LR: 0.000001\n",
      "Bin 1, Epoch 301/600, Train Loss: 0.7028, Validation Loss: 0.7284,  ValAccuracy: 0.2175, LR: 0.000001\n",
      "Bin 1, Epoch 311/600, Train Loss: 0.6963, Validation Loss: 0.7284,  ValAccuracy: 0.2175, LR: 0.000001\n",
      "Bin 1, Epoch 321/600, Train Loss: 0.6995, Validation Loss: 0.7284,  ValAccuracy: 0.2175, LR: 0.000001\n",
      "Bin 1, Epoch 331/600, Train Loss: 0.6993, Validation Loss: 0.7284,  ValAccuracy: 0.2175, LR: 0.000001\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 29\u001b[0m\n\u001b[1;32m     26\u001b[0m validation_accuracies \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m     28\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(epochs):\n\u001b[0;32m---> 29\u001b[0m     epoch_loss, accuracy \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     30\u001b[0m     validation_loss, validation_accuracy, attention_data \u001b[38;5;241m=\u001b[39m validate_model(model, val_loader, criterion, device)\n\u001b[1;32m     31\u001b[0m     \u001b[38;5;66;03m#scheduler.step(validation_loss)\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[2], line 7\u001b[0m, in \u001b[0;36mtrain_model\u001b[0;34m(model, dataloader, criterion, optimizer, device)\u001b[0m\n\u001b[1;32m      4\u001b[0m total \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m      5\u001b[0m correct \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m----> 7\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m batch \u001b[38;5;129;01min\u001b[39;00m dataloader:\n\u001b[1;32m      8\u001b[0m     batch \u001b[38;5;241m=\u001b[39m batch\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m     10\u001b[0m     optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n",
      "File \u001b[0;32m~/miniconda3/envs/cpp-ml/lib/python3.9/site-packages/torch/utils/data/dataloader.py:701\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    698\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    699\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    700\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 701\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    702\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    703\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m    704\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable\n\u001b[1;32m    705\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    706\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called\n\u001b[1;32m    707\u001b[0m ):\n",
      "File \u001b[0;32m~/miniconda3/envs/cpp-ml/lib/python3.9/site-packages/torch/utils/data/dataloader.py:757\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    755\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    756\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m--> 757\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m    758\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[1;32m    759\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[0;32m~/miniconda3/envs/cpp-ml/lib/python3.9/site-packages/torch/utils/data/_utils/fetch.py:55\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     54\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n\u001b[0;32m---> 55\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcollate_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/cpp-ml/lib/python3.9/site-packages/torch_geometric/loader/dataloader.py:27\u001b[0m, in \u001b[0;36mCollater.__call__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m     25\u001b[0m elem \u001b[38;5;241m=\u001b[39m batch[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m     26\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(elem, BaseData):\n\u001b[0;32m---> 27\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mBatch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_data_list\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     28\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     29\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfollow_batch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfollow_batch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     30\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexclude_keys\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexclude_keys\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     31\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     32\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(elem, torch\u001b[38;5;241m.\u001b[39mTensor):\n\u001b[1;32m     33\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m default_collate(batch)\n",
      "File \u001b[0;32m~/miniconda3/envs/cpp-ml/lib/python3.9/site-packages/torch_geometric/data/batch.py:97\u001b[0m, in \u001b[0;36mBatch.from_data_list\u001b[0;34m(cls, data_list, follow_batch, exclude_keys)\u001b[0m\n\u001b[1;32m     82\u001b[0m \u001b[38;5;129m@classmethod\u001b[39m\n\u001b[1;32m     83\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfrom_data_list\u001b[39m(\n\u001b[1;32m     84\u001b[0m     \u001b[38;5;28mcls\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     87\u001b[0m     exclude_keys: Optional[List[\u001b[38;5;28mstr\u001b[39m]] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m     88\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Self:\n\u001b[1;32m     89\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Constructs a :class:`~torch_geometric.data.Batch` object from a\u001b[39;00m\n\u001b[1;32m     90\u001b[0m \u001b[38;5;124;03m    list of :class:`~torch_geometric.data.Data` or\u001b[39;00m\n\u001b[1;32m     91\u001b[0m \u001b[38;5;124;03m    :class:`~torch_geometric.data.HeteroData` objects.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     95\u001b[0m \u001b[38;5;124;03m    Will exclude any keys given in :obj:`exclude_keys`.\u001b[39;00m\n\u001b[1;32m     96\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m---> 97\u001b[0m     batch, slice_dict, inc_dict \u001b[38;5;241m=\u001b[39m \u001b[43mcollate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     98\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     99\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdata_list\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata_list\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    100\u001b[0m \u001b[43m        \u001b[49m\u001b[43mincrement\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    101\u001b[0m \u001b[43m        \u001b[49m\u001b[43madd_batch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43misinstance\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mdata_list\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mBatch\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    102\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfollow_batch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfollow_batch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    103\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexclude_keys\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mexclude_keys\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    104\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    106\u001b[0m     batch\u001b[38;5;241m.\u001b[39m_num_graphs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(data_list)  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[1;32m    107\u001b[0m     batch\u001b[38;5;241m.\u001b[39m_slice_dict \u001b[38;5;241m=\u001b[39m slice_dict  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/cpp-ml/lib/python3.9/site-packages/torch_geometric/data/collate.py:56\u001b[0m, in \u001b[0;36mcollate\u001b[0;34m(cls, data_list, increment, add_batch, follow_batch, exclude_keys)\u001b[0m\n\u001b[1;32m     53\u001b[0m     data_list \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(data_list)\n\u001b[1;32m     55\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcls\u001b[39m \u001b[38;5;241m!=\u001b[39m data_list[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m:  \u001b[38;5;66;03m# Dynamic inheritance.\u001b[39;00m\n\u001b[0;32m---> 56\u001b[0m     out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m_base_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata_list\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;18;43m__class__\u001b[39;49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[1;32m     57\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     58\u001b[0m     out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mcls\u001b[39m()\n",
      "File \u001b[0;32m~/miniconda3/envs/cpp-ml/lib/python3.9/site-packages/torch_geometric/data/batch.py:39\u001b[0m, in \u001b[0;36mDynamicInheritance.__call__\u001b[0;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[1;32m     36\u001b[0m         \u001b[38;5;28mglobals\u001b[39m()[name] \u001b[38;5;241m=\u001b[39m MetaResolver(name, (\u001b[38;5;28mcls\u001b[39m, base_cls), {})\n\u001b[1;32m     37\u001b[0m     new_cls \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mglobals\u001b[39m()[name]\n\u001b[0;32m---> 39\u001b[0m params \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[43minspect\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msignature\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbase_cls\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mparameters\u001b[38;5;241m.\u001b[39mitems())\n\u001b[1;32m     40\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, (k, v) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(params[\u001b[38;5;241m1\u001b[39m:]):\n\u001b[1;32m     41\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m k \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124margs\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m k \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mkwargs\u001b[39m\u001b[38;5;124m'\u001b[39m:\n",
      "File \u001b[0;32m~/miniconda3/envs/cpp-ml/lib/python3.9/inspect.py:3113\u001b[0m, in \u001b[0;36msignature\u001b[0;34m(obj, follow_wrapped)\u001b[0m\n\u001b[1;32m   3111\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msignature\u001b[39m(obj, \u001b[38;5;241m*\u001b[39m, follow_wrapped\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[1;32m   3112\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Get a signature object for the passed callable.\"\"\"\u001b[39;00m\n\u001b[0;32m-> 3113\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mSignature\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_callable\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfollow_wrapped\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfollow_wrapped\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/cpp-ml/lib/python3.9/inspect.py:2862\u001b[0m, in \u001b[0;36mSignature.from_callable\u001b[0;34m(cls, obj, follow_wrapped)\u001b[0m\n\u001b[1;32m   2859\u001b[0m \u001b[38;5;129m@classmethod\u001b[39m\n\u001b[1;32m   2860\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfrom_callable\u001b[39m(\u001b[38;5;28mcls\u001b[39m, obj, \u001b[38;5;241m*\u001b[39m, follow_wrapped\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[1;32m   2861\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Constructs Signature for the given callable object.\"\"\"\u001b[39;00m\n\u001b[0;32m-> 2862\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_signature_from_callable\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msigcls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2863\u001b[0m \u001b[43m                                    \u001b[49m\u001b[43mfollow_wrapper_chains\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfollow_wrapped\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/cpp-ml/lib/python3.9/inspect.py:2325\u001b[0m, in \u001b[0;36m_signature_from_callable\u001b[0;34m(obj, follow_wrapper_chains, skip_bound_arg, sigcls)\u001b[0m\n\u001b[1;32m   2320\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m sig\u001b[38;5;241m.\u001b[39mreplace(parameters\u001b[38;5;241m=\u001b[39mnew_params)\n\u001b[1;32m   2322\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m isfunction(obj) \u001b[38;5;129;01mor\u001b[39;00m _signature_is_functionlike(obj):\n\u001b[1;32m   2323\u001b[0m     \u001b[38;5;66;03m# If it's a pure Python function, or an object that is duck type\u001b[39;00m\n\u001b[1;32m   2324\u001b[0m     \u001b[38;5;66;03m# of a Python function (Cython functions, for instance), then:\u001b[39;00m\n\u001b[0;32m-> 2325\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_signature_from_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43msigcls\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2326\u001b[0m \u001b[43m                                    \u001b[49m\u001b[43mskip_bound_arg\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mskip_bound_arg\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2328\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _signature_is_builtin(obj):\n\u001b[1;32m   2329\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _signature_from_builtin(sigcls, obj,\n\u001b[1;32m   2330\u001b[0m                                    skip_bound_arg\u001b[38;5;241m=\u001b[39mskip_bound_arg)\n",
      "File \u001b[0;32m~/miniconda3/envs/cpp-ml/lib/python3.9/inspect.py:2241\u001b[0m, in \u001b[0;36m_signature_from_function\u001b[0;34m(cls, func, skip_bound_arg)\u001b[0m\n\u001b[1;32m   2236\u001b[0m     parameters\u001b[38;5;241m.\u001b[39mappend(Parameter(name, annotation\u001b[38;5;241m=\u001b[39mannotation,\n\u001b[1;32m   2237\u001b[0m                                 kind\u001b[38;5;241m=\u001b[39m_VAR_KEYWORD))\n\u001b[1;32m   2239\u001b[0m \u001b[38;5;66;03m# Is 'func' is a pure Python function - don't validate the\u001b[39;00m\n\u001b[1;32m   2240\u001b[0m \u001b[38;5;66;03m# parameters list (for correct order and defaults), it should be OK.\u001b[39;00m\n\u001b[0;32m-> 2241\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2242\u001b[0m \u001b[43m           \u001b[49m\u001b[43mreturn_annotation\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mannotations\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mreturn\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_empty\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2243\u001b[0m \u001b[43m           \u001b[49m\u001b[43m__validate_parameters__\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_duck_function\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/cpp-ml/lib/python3.9/inspect.py:2781\u001b[0m, in \u001b[0;36mSignature.__init__\u001b[0;34m(self, parameters, return_annotation, __validate_parameters__)\u001b[0m\n\u001b[1;32m   2777\u001b[0m _bound_arguments_cls \u001b[38;5;241m=\u001b[39m BoundArguments\n\u001b[1;32m   2779\u001b[0m empty \u001b[38;5;241m=\u001b[39m _empty\n\u001b[0;32m-> 2781\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, parameters\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m, return_annotation\u001b[38;5;241m=\u001b[39m_empty,\n\u001b[1;32m   2782\u001b[0m              __validate_parameters__\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[1;32m   2783\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Constructs Signature from the given list of Parameter\u001b[39;00m\n\u001b[1;32m   2784\u001b[0m \u001b[38;5;124;03m    objects and 'return_annotation'.  All arguments are optional.\u001b[39;00m\n\u001b[1;32m   2785\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m   2787\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m parameters \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Define paths for saving models\n",
    "save_dir = \"GATModels-5A-v2\"\n",
    "os.makedirs(f\"{save_dir}/Models\", exist_ok=True)\n",
    "os.makedirs(f\"{save_dir}/Weights\", exist_ok=True)\n",
    "\n",
    "epochs = 600\n",
    "batch_size = 256\n",
    "\n",
    "val_loader = DataLoader(validation_graphs, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "for i, bin in enumerate(bins, start=0):\n",
    "    model = GAT(in_channels=37, out_channels=16).to(device)\n",
    "    criterion = nn.BCELoss()  \n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.000001, weight_decay=1e-4)\n",
    "    #scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=10, threshold=1e-4)\n",
    "\n",
    "    train_loader = DataLoader(bin, batch_size=batch_size, shuffle=True)    \n",
    "\n",
    "    print(f\"Training on bin {i+1}/{len(bins)}\")\n",
    "\n",
    "    train_losses = []\n",
    "    learning_rates = []\n",
    "    validation_losses = []\n",
    "    validation_accuracies = []\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        epoch_loss, accuracy = train_model(model, train_loader, criterion, optimizer, device)\n",
    "        validation_loss, validation_accuracy, attention_data = validate_model(model, val_loader, criterion, device)\n",
    "        #scheduler.step(validation_loss)\n",
    "        \n",
    "        current_lr = optimizer.param_groups[0]['lr'] \n",
    "        train_losses.append(epoch_loss)\n",
    "        learning_rates.append(current_lr)\n",
    "        validation_losses.append(validation_loss)\n",
    "        validation_accuracies.append(validation_accuracy)   \n",
    "        if epoch % 10 == 0:\n",
    "            print(\n",
    "                f\"Bin {i+1}, Epoch {epoch+1}/{epochs}, \"\n",
    "                f\"Train Loss: {epoch_loss:.4f}, Validation Loss: {validation_loss:.4f},  \"\n",
    "                f\"ValAccuracy: {validation_accuracy:.4f}, \"\n",
    "                f\"LR: {current_lr:.6f}\"\n",
    "            )\n",
    "                \n",
    "    plot_graphs(train_losses, validation_losses, validation_accuracies, learning_rates)\n",
    "\n",
    "    #Save the trained model\n",
    "    model_path = os.path.join(save_dir, f\"Models/model_bin_{i+1}.pth\")\n",
    "    torch.save(model.state_dict(), model_path)\n",
    "    print(f\"Model for bin {i+1} saved to {model_path}\")\n",
    "\n",
    "    # Save attention weights\n",
    "    attn_path = os.path.join(save_dir, f\"Weights/attn_bin_{i+1}.pt\")\n",
    "    torch.save(attention_data, attn_path)\n",
    "    print(f\"Attention weights for bin {i+1} saved to {attn_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "419ac395-269a-4473-b4bb-41b51cfd8d4f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cpp-ml",
   "language": "python",
   "name": "cpp-ml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
