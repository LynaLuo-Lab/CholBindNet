{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "94a3808a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch_geometric.data import Data, DataLoader\n",
    "from torch_geometric.loader import DataLoader\n",
    "from torch_geometric.nn import GATConv, global_mean_pool, GCNConv\n",
    "import glob\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import torch.nn.functional as F\n",
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "# Define GAT model for batched data\n",
    "class GAT(torch.nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, dropout_p=0.1):\n",
    "        super().__init__()\n",
    "        self.gat = GATConv(in_channels, out_channels, heads=1, concat=True, edge_dim=1)\n",
    "        self.pool = global_mean_pool  # Can also use global_max_pool or global_add_pool\n",
    "        self.dropout = nn.Dropout(p=dropout_p)\n",
    "        self.norm = nn.BatchNorm1d(out_channels)\n",
    "        self.linear = torch.nn.Linear(out_channels, 1)\n",
    "\n",
    "    def forward(self, x, edge_index, edge_attr, batch):\n",
    "        out, attn_weights = self.gat(x, edge_index, edge_attr, return_attention_weights=True)\n",
    "        out = self.dropout(out)\n",
    "        out = self.pool(out, batch)  # Pool over nodes in each graph\n",
    "        out = self.norm(out)\n",
    "        out = self.dropout(out) \n",
    "        out = self.linear(out)\n",
    "        return out, attn_weights\n",
    "\n",
    "def gat_organize_graph_and_add_weight(file_path, label):\n",
    "    data = np.load(file_path, allow_pickle=True).item()\n",
    "    inverse_distance = data['inverse_distance']\n",
    "    encoded_matrix = data['encoded_matrix']\n",
    "\n",
    "    x = torch.tensor(encoded_matrix, dtype=torch.float32)\n",
    "    adj = torch.tensor(inverse_distance, dtype=torch.float32)\n",
    "\n",
    "    # Normalize adjacency (row-normalize)\n",
    "    adj = adj / (adj.sum(dim=1, keepdim=True) + 1e-8)\n",
    "\n",
    "    # Create edge_index and edge weights\n",
    "    edge_index = (adj > 0).nonzero(as_tuple=False).t()\n",
    "    edge_weight = adj[adj > 0]\n",
    "\n",
    "    y = torch.tensor([label], dtype=torch.float32)\n",
    "    \n",
    "    return Data(x=x, edge_index=edge_index, edge_attr=edge_weight, y=y)\n",
    "\n",
    "class GCN(nn.Module):\n",
    "    def __init__(self, input_dim):\n",
    "        super(GCN, self).__init__()\n",
    "        self.conv1 = GCNConv(input_dim, 32)\n",
    "        self.bn1 = nn.BatchNorm1d(32)\n",
    "        \n",
    "        self.conv2 = GCNConv(32, 64)\n",
    "        self.bn2 = nn.BatchNorm1d(64)\n",
    "        \n",
    "        self.conv3 = GCNConv(64, 128)\n",
    "        self.bn3 = nn.BatchNorm1d(128)\n",
    "\n",
    "        self.dropout_gcn = nn.Dropout(0.2)\n",
    "        self.dropout = nn.Dropout(0.6)\n",
    "        \n",
    "        self.fc1 = nn.Linear(128, 64)\n",
    "        self.out = nn.Linear(64, 1)\n",
    "\n",
    "    def forward(self, data):\n",
    "        x, edge_index, edge_weight, batch = data.x, data.edge_index, data.edge_attr, data.batch\n",
    "\n",
    "        x = self.conv1(x, edge_index, edge_weight)\n",
    "        x = self.bn1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.dropout_gcn(x)\n",
    "\n",
    "        x = self.conv2(x, edge_index, edge_weight)\n",
    "        x = self.bn2(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.dropout_gcn(x)\n",
    "\n",
    "        x = self.conv3(x, edge_index, edge_weight)\n",
    "        x = self.bn3(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.dropout_gcn(x)\n",
    "\n",
    "        # Global pooling to get graph-level representation\n",
    "        x = global_mean_pool(x, batch)\n",
    "\n",
    "        x = self.fc1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.out(x)\n",
    "\n",
    "        return x\n",
    "    \n",
    "def gcn_organize_graph_and_add_weight(file_path, label):\n",
    "    data = np.load(file_path, allow_pickle=True).item()\n",
    "    inverse_distance = data['inverse_distance']\n",
    "    encoded_matrix = data['encoded_matrix']\n",
    "\n",
    "    x = torch.tensor(encoded_matrix, dtype=torch.float32)\n",
    "    adj = torch.tensor(inverse_distance, dtype=torch.float32)\n",
    "\n",
    "    # Normalize adjacency (row-normalize)\n",
    "    #adj = adj / (adj.sum(dim=1, keepdim=True) + 1e-8)\n",
    "\n",
    "    # Create edge_index and edge weights\n",
    "    edge_index = (adj > 0).nonzero(as_tuple=False).t()\n",
    "    edge_weight = adj[adj > 0]\n",
    "\n",
    "    y = torch.tensor([label], dtype=torch.float32)\n",
    "    \n",
    "    return Data(x=x, edge_index=edge_index, edge_attr=edge_weight, y=y)\n",
    "\n",
    "# Define the 2D CNN model in PyTorch\n",
    "class CNN2D(nn.Module):\n",
    "    def __init__(self, input_channels):\n",
    "        super(CNN2D, self).__init__()\n",
    "        self.conv1 = nn.Sequential(\n",
    "            nn.Conv2d(input_channels, 32, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        self.pool1 = nn.MaxPool2d(2, 2)\n",
    "        \n",
    "        self.conv2 = nn.Sequential(\n",
    "            nn.Conv2d(32, 64, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        self.pool2 = nn.MaxPool2d(2, 2)\n",
    "        \n",
    "        self.conv3 = nn.Sequential(\n",
    "            nn.Conv2d(64, 128, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        self.pool3 = nn.MaxPool2d(2, 2)\n",
    "        \n",
    "        self.flatten = nn.Flatten()\n",
    "        self.fc1 = nn.Linear(128 * 25 * 8, 128)\n",
    "\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "        self.fc2 = nn.Linear(128, 1)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.pool1(x)\n",
    "        \n",
    "        x = self.conv2(x)\n",
    "        x = self.pool2(x)\n",
    "        \n",
    "        x = self.conv3(x)\n",
    "        x = self.pool3(x)\n",
    "        \n",
    "        x = self.flatten(x)\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc2(x)\n",
    "\n",
    "        return x\n",
    "    \n",
    "class CNN3D(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN3D, self).__init__()\n",
    "        \n",
    "        self.conv0 = nn.Conv3d(in_channels=65, out_channels=64, kernel_size=1, stride=1, padding=0) # play around with output channels\n",
    "        self.conv1 = nn.Conv3d(in_channels=64, out_channels=64, kernel_size=3, stride=1, padding=1)\n",
    "        self.pool = nn.MaxPool3d(kernel_size=2, stride=2, padding=0)\n",
    "        self.conv2 = nn.Conv3d(in_channels=64, out_channels=128, kernel_size=3, stride=1, padding=1)\n",
    "        self.pool2 = nn.MaxPool3d(kernel_size=2, stride=2, padding=0)\n",
    "\n",
    "        #self.dropout_conv = nn.Dropout3d(p=0.05)\n",
    "        \n",
    "        # After two pooling layers, spatial dimensions reduce from 40x40x40 -> 5x5x5\n",
    "        self.fc1 = nn.Linear(128 * 4 * 4 * 4, 256)  # Try increasing over 256\n",
    "        self.fc2 = nn.Linear(256, 128)\n",
    "        self.fc3 = nn.Linear(128, 2)  # Assuming 1 output for docking status/position\n",
    "\n",
    "        #self.dropout_fc = nn.Dropout(p=0.15)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # Forward pass through Conv layers\n",
    "        x = self.pool(torch.relu(self.conv0(x)))  # Conv0 -> ReLU -> Pooling\n",
    "        #x = self.dropout_conv(x)\n",
    "        x = self.pool(torch.relu(self.conv1(x)))  # Conv1 -> ReLU -> Pooling\n",
    "        x = self.pool2(torch.relu(self.conv2(x)))  # Conv2 -> ReLU -> Pooling\n",
    "\n",
    "        # Flatten the input for fully connected layers\n",
    "        x = x.view(-1, 128 * 4 * 4 * 4)\n",
    "        \n",
    "        # Forward pass through fully connected layers\n",
    "        x = torch.relu(self.fc1(x)) #use tanh activation\n",
    "        #x = self.dropout_fc(x)\n",
    "        x = torch.relu(self.fc2(x))\n",
    "        x = torch.nn.functional.softmax(self.fc3(x), dim=1)  # Final layer (output layer)\n",
    "        #x = torch.clamp(x, min=1e-7, max=1 - 1e-7)  # Clamp outputs to avoid extreme values\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "57fccafc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda\n"
     ]
    }
   ],
   "source": [
    "# -----------------------------\n",
    "# Per-experiment spies dirs\n",
    "# -----------------------------\n",
    "gat_gcn_spies_exps = [\n",
    "    \"../CLR_Ligand_Data/cholesterol-separate-graphs-clr_exp1/Spies\",\n",
    "    \"../CLR_Ligand_Data/cholesterol-separate-graphs-clr_exp2/Spies\",\n",
    "    \"../CLR_Ligand_Data/cholesterol-separate-graphs-clr_exp3/Spies\",\n",
    "    \"../CLR_Ligand_Data/cholesterol-separate-graphs-clr_exp4/Spies\",\n",
    "    \"../CLR_Ligand_Data/cholesterol-separate-graphs-clr_exp5/Spies\",\n",
    "]\n",
    "\n",
    "gnn_spies_exps = [\n",
    "    \"../CLR_Ligand_Data/cholesterol-graph-clr_exp1/Spies\",\n",
    "    \"../CLR_Ligand_Data/cholesterol-graph-clr_exp2/Spies\",\n",
    "    \"../CLR_Ligand_Data/cholesterol-graph-clr_exp3/Spies\",\n",
    "    \"../CLR_Ligand_Data/cholesterol-graph-clr_exp4/Spies\",\n",
    "    \"../CLR_Ligand_Data/cholesterol-graph-clr_exp5/Spies\",\n",
    "]\n",
    "\n",
    "cnn_spies_exps = [\n",
    "    \"../CLR_Ligand_Data/total-grid-5A-clr_exp1/Spies\",\n",
    "    \"../CLR_Ligand_Data/total-grid-5A-clr_exp2/Spies\"\n",
    "]\n",
    "\n",
    "# eval dirs (these typically don't change per exp)\n",
    "gat_gcn_unlabeled = \"Data/cholesterol-separate-sep-clr/unlabeled\"\n",
    "gnn_unlabeled     = \"Data/cholesterol-sep-clr/unlabeled\"\n",
    "cnn_unlabeled     = \"Data/total-sep-5A-clr/unlabeled\"\n",
    "\n",
    "OUT_ROOT = \"./PU_EvalOutputs_Ensemble\"\n",
    "os.makedirs(OUT_ROOT, exist_ok=True)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Device:\", device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2f01139d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------\n",
    "# File helpers\n",
    "# -----------------------------\n",
    "def list_npy_files(dir_path: str):\n",
    "    return sorted(glob.glob(os.path.join(dir_path, \"*.npy\")))\n",
    "\n",
    "def load_npy_dict(file_path: str):\n",
    "    return np.load(file_path, allow_pickle=True).item()\n",
    "\n",
    "def load_cnn_matrix(file_path: str) -> np.ndarray:\n",
    "    x = np.load(file_path, allow_pickle=True)\n",
    "    # Must be a numeric 2D matrix\n",
    "    if not isinstance(x, np.ndarray):\n",
    "        raise ValueError(f\"CNN file did not load as ndarray: {file_path}, type={type(x)}\")\n",
    "    if x.ndim != 2:\n",
    "        raise ValueError(f\"CNN matrix must be 2D: {file_path}, got shape {x.shape}\")\n",
    "    if x.dtype == object:\n",
    "        raise ValueError(f\"CNN matrix should not be dtype=object: {file_path}, got dtype=object with shape {x.shape}\")\n",
    "    return x\n",
    "\n",
    "def infer_graph_input_dim(dir_path: str) -> int:\n",
    "    files = list_npy_files(dir_path)\n",
    "    if not files:\n",
    "        raise FileNotFoundError(f\"No .npy files found in: {dir_path}\")\n",
    "    d = load_npy_dict(files[0])\n",
    "    return int(d[\"encoded_matrix\"].shape[1])\n",
    "\n",
    "def organize_graph(file_path: str, normalize_adj: bool) -> Data:\n",
    "    data = np.load(file_path, allow_pickle=True).item()\n",
    "    adj = torch.tensor(data['inverse_distance'], dtype=torch.float32)\n",
    "    x = torch.tensor(data['encoded_matrix'], dtype=torch.float32)\n",
    "\n",
    "    if normalize_adj:\n",
    "        adj = adj / (adj.sum(dim=1, keepdim=True) + 1e-8)\n",
    "\n",
    "    edge_index = (adj > 0).nonzero(as_tuple=False).t()\n",
    "    edge_weight = adj[adj > 0]\n",
    "    return Data(x=x, edge_index=edge_index, edge_attr=edge_weight)\n",
    "\n",
    "def ensure_dir(p: str):\n",
    "    os.makedirs(p, exist_ok=True)\n",
    "\n",
    "# -----------------------------\n",
    "# Labeling method (from spies percentiles)\n",
    "# -----------------------------\n",
    "def compute_spy_percentiles(spy_probs: np.ndarray):\n",
    "    p25, p50, p75 = np.percentile(spy_probs, [25, 50, 75])\n",
    "    return {\n",
    "        \"p25\": float(p25),\n",
    "        \"p50\": float(p50),\n",
    "        \"p75\": float(p75),\n",
    "        \"n_spies\": int(len(spy_probs)),\n",
    "        \"min\": float(np.min(spy_probs)) if len(spy_probs) else None,\n",
    "        \"max\": float(np.max(spy_probs)) if len(spy_probs) else None,\n",
    "        \"mean\": float(np.mean(spy_probs)) if len(spy_probs) else None,\n",
    "        \"std\": float(np.std(spy_probs)) if len(spy_probs) else None,\n",
    "    }\n",
    "\n",
    "def label_from_percentiles(prob: float, stats: dict) -> str:\n",
    "    p25, p50, p75 = stats[\"p25\"], stats[\"p50\"], stats[\"p75\"]\n",
    "    if prob <= p25:\n",
    "        return \"Negative\"\n",
    "    elif prob <= p50:\n",
    "        return \"PseudoNegative\"\n",
    "    elif prob <= p75:\n",
    "        return \"PseudoPositive\"\n",
    "    else:\n",
    "        return \"Positive\"\n",
    "\n",
    "def plot_label_histogram(df: pd.DataFrame, title: str, out_png: str):\n",
    "    order = [\"Negative\", \"PseudoNegative\", \"PseudoPositive\", \"Positive\"]\n",
    "    counts = df[\"label\"].value_counts().reindex(order, fill_value=0)\n",
    "    plt.figure()\n",
    "    plt.bar(counts.index.tolist(), counts.values.tolist())\n",
    "    plt.title(title)\n",
    "    plt.xlabel(\"Label\")\n",
    "    plt.ylabel(\"Count\")\n",
    "    plt.xticks(rotation=20, ha=\"right\")\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(out_png, dpi=200)\n",
    "    plt.close()\n",
    "\n",
    "def resolve_ensemble_checkpoints(pattern_or_dir: str) -> list[str]:\n",
    "    \"\"\"\n",
    "    Give either:\n",
    "      - a glob pattern:  \"/path/to/gat_submodels/*.pt\"\n",
    "      - or a directory: \"/path/to/gat_submodels\"\n",
    "    \"\"\"\n",
    "    if os.path.isdir(pattern_or_dir):\n",
    "        ckpts = sorted(glob.glob(os.path.join(pattern_or_dir, \"*.pt\"))) + \\\n",
    "                sorted(glob.glob(os.path.join(pattern_or_dir, \"*.pth\")))\n",
    "    else:\n",
    "        ckpts = sorted(glob.glob(pattern_or_dir))\n",
    "    if len(ckpts) == 0:\n",
    "        raise FileNotFoundError(f\"No checkpoints found for: {pattern_or_dir}\")\n",
    "    return ckpts\n",
    "\n",
    "def load_state_dict_into(model: nn.Module, ckpt_path: str):\n",
    "    sd = torch.load(ckpt_path, map_location=\"cpu\")\n",
    "    # supports either raw state_dict or a dict with 'model_state_dict'\n",
    "    if isinstance(sd, dict) and \"model_state_dict\" in sd:\n",
    "        sd = sd[\"model_state_dict\"]\n",
    "    model.load_state_dict(sd)\n",
    "    return model\n",
    "\n",
    "from collections import Counter\n",
    "\n",
    "def majority_vote(labels: list[str]) -> str:\n",
    "    c = Counter(labels)\n",
    "    # deterministic tie-breaker by fixed priority order\n",
    "    order = [\"Negative\", \"PseudoNegative\", \"PseudoPositive\", \"Positive\"]\n",
    "    best = max(order, key=lambda k: (c.get(k, 0), -order.index(k)))\n",
    "    return best\n",
    "\n",
    "def run_pu_eval_5exp_with_exp_spies(\n",
    "    model_name: str,\n",
    "    out_dir: str,\n",
    "    spies_dirs: list[str],          # len=2\n",
    "    eval_dir: str,\n",
    "    predict_rows_fn_per_exp,        # fn(files, exp_idx)-> rows using THAT exp ckpts\n",
    "):\n",
    "    ensure_dir(out_dir)\n",
    "\n",
    "    eval_files = list_npy_files(eval_dir)\n",
    "    if len(eval_files) == 0:\n",
    "        raise FileNotFoundError(f\"[{model_name}] no eval files in {eval_dir}\")\n",
    "\n",
    "    exp_eval_probs = []   # list of np.array [n_files] per exp\n",
    "    exp_eval_labels = []  # list of list[str] per exp\n",
    "    exp_spy_stats = []\n",
    "\n",
    "    for exp_idx, spies_dir in enumerate(spies_dirs):\n",
    "        spy_files = list_npy_files(spies_dir)\n",
    "        if len(spy_files) == 0:\n",
    "            raise FileNotFoundError(f\"[{model_name}] no spies in {spies_dir}\")\n",
    "\n",
    "        print(f\"\\n[{model_name}] EXP {exp_idx+1}/2: spies={len(spy_files)} eval={len(eval_files)}\")\n",
    "\n",
    "        # 1) predict spies (with this experiment's ckpts)\n",
    "        spy_rows = predict_rows_fn_per_exp(spy_files, exp_idx)\n",
    "        spy_probs = np.array([r[\"prob\"] for r in spy_rows], dtype=float)\n",
    "\n",
    "        stats = compute_spy_percentiles(spy_probs)\n",
    "        stats[\"model\"] = model_name\n",
    "        stats[\"exp_idx\"] = exp_idx + 1\n",
    "        stats[\"spies_dir\"] = spies_dir\n",
    "        exp_spy_stats.append(stats)\n",
    "\n",
    "        # 2) predict eval (with this experiment's ckpts)\n",
    "        eval_rows = predict_rows_fn_per_exp(eval_files, exp_idx)\n",
    "        probs = np.array([r[\"prob\"] for r in eval_rows], dtype=np.float64)\n",
    "\n",
    "        # 3) label eval with THIS experiment's thresholds\n",
    "        labels = [label_from_percentiles(float(p), stats) for p in probs]\n",
    "\n",
    "        exp_eval_probs.append(probs)\n",
    "        exp_eval_labels.append(labels)\n",
    "\n",
    "        print(f\"  thresholds: p25={stats['p25']:.4f}, p50={stats['p50']:.4f}, p75={stats['p75']:.4f}\")\n",
    "\n",
    "    # Stack to [2, n_files]\n",
    "    exp_eval_probs = np.stack(exp_eval_probs, axis=0)\n",
    "    prob_mean = exp_eval_probs.mean(axis=0)\n",
    "    prob_std  = exp_eval_probs.std(axis=0, ddof=0)\n",
    "\n",
    "    # Majority label vote across the 2 experiments\n",
    "    labels_majority = []\n",
    "    for i in range(len(eval_files)):\n",
    "        labels_i = [exp_eval_labels[e][i] for e in range(2)]\n",
    "        labels_majority.append(majority_vote(labels_i))\n",
    "\n",
    "    # Save combined outputs\n",
    "    out_rows = []\n",
    "    for i, fp in enumerate(eval_files):\n",
    "        row = {\n",
    "            \"file\": os.path.basename(fp),\n",
    "            \"path\": fp,\n",
    "            \"prob\": float(prob_mean[i]),\n",
    "            \"prob_std\": float(prob_std[i]),\n",
    "            \"label\": labels_majority[i],\n",
    "        }\n",
    "        # optional: keep per-exp probs for debugging\n",
    "        for e in range(2):\n",
    "            row[f\"prob_exp{e+1}\"] = float(exp_eval_probs[e, i])\n",
    "        out_rows.append(row)\n",
    "\n",
    "    df_eval = pd.DataFrame(out_rows)\n",
    "    out_csv = os.path.join(out_dir, f\"{model_name}_eval_probs_and_labels.csv\")\n",
    "    df_eval.to_csv(out_csv, index=False)\n",
    "\n",
    "    # Save spies stats (per exp)\n",
    "    pd.DataFrame(exp_spy_stats).to_csv(os.path.join(out_dir, f\"{model_name}_spies_stats_2exp.csv\"), index=False)\n",
    "    with open(os.path.join(out_dir, f\"{model_name}_spies_stats_5exp.json\"), \"w\") as f:\n",
    "        json.dump(exp_spy_stats, f, indent=2)\n",
    "\n",
    "    out_png = os.path.join(out_dir, f\"{model_name}_eval_label_hist_5exp.png\")\n",
    "    plot_label_histogram(df_eval, f\"{model_name} label counts (mean prob across 2 exps; majority label)\", out_png)\n",
    "\n",
    "    print(f\"\\n[{model_name}] majority label counts:\\n{df_eval['label'].value_counts()}\")\n",
    "    print(f\"Saved: {out_csv}\")\n",
    "    print(f\"Saved: {out_png}\")\n",
    "    print(f\"Saved: {os.path.join(out_dir, f'{model_name}_spies_stats_5exp.json')}\")\n",
    "\n",
    "def load_grid_3d(file_path: str) -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    Loads a (D,H,W,C) numpy grid and returns torch tensor [C,D,H,W] float32.\n",
    "    Matches your training: torch.tensor(grid).permute(3,0,1,2)\n",
    "    \"\"\"\n",
    "    arr = np.load(file_path)\n",
    "    if not isinstance(arr, np.ndarray):\n",
    "        raise ValueError(f\"3DCNN grid did not load as ndarray: {file_path}\")\n",
    "    if arr.ndim != 4:\n",
    "        raise ValueError(f\"3DCNN grid must be 4D (D,H,W,C). Got shape {arr.shape} for {file_path}\")\n",
    "    x = torch.tensor(arr, dtype=torch.float32).permute(3, 0, 1, 2)  # [C,D,H,W]\n",
    "    return x\n",
    "\n",
    "@torch.no_grad()\n",
    "def ensemble_predict_probs_cnn3d(\n",
    "    ckpt_paths: list[str],\n",
    "    files: list[str],\n",
    "    batch_size: int = 8,\n",
    ") -> list[dict]:\n",
    "    \"\"\"\n",
    "    Averages PROBABILITIES across 3DCNN submodels.\n",
    "    Uses P(class=1) from softmax output.\n",
    "    \"\"\"\n",
    "    if len(files) == 0:\n",
    "        return []\n",
    "\n",
    "    prob_sum = np.zeros(len(files), dtype=np.float64)\n",
    "\n",
    "    for k, ckpt in enumerate(ckpt_paths):\n",
    "        model = CNN3D().to(device)\n",
    "        model = load_state_dict_into(model, ckpt)\n",
    "        model.eval()\n",
    "\n",
    "        for i in range(0, len(files), batch_size):\n",
    "            batch_files = files[i:i+batch_size]\n",
    "            xs = [load_grid_3d(fp) for fp in batch_files]\n",
    "            x_batch = torch.stack(xs, dim=0).to(device)  # [B,C,D,H,W]\n",
    "\n",
    "            out = model(x_batch)              # [B,2] softmax\n",
    "            probs = out[:, 1].detach().cpu().numpy()  # P(class=1)\n",
    "\n",
    "            prob_sum[i:i+len(probs)] += probs\n",
    "\n",
    "        print(f\"  submodel {k+1}/{len(ckpt_paths)} done: {os.path.basename(ckpt)}\")\n",
    "\n",
    "    prob_avg = prob_sum / float(len(ckpt_paths))\n",
    "    return [{\"file\": os.path.basename(fp), \"path\": fp, \"prob\": float(prob_avg[i])}\n",
    "            for i, fp in enumerate(files)]\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def ensemble_predict_probs_graph(\n",
    "    model_ctor,\n",
    "    gat_bool,\n",
    "    ckpt_paths: list[str],\n",
    "    files: list[str],\n",
    "    batch_size: int = 16,\n",
    "    num_workers: int = 0,\n",
    ") -> list[dict]:\n",
    "\n",
    "    if len(files) == 0:\n",
    "        return []\n",
    "\n",
    "    data_list = [organize_graph(fp, gat_bool) for fp in files]\n",
    "    loader = DataLoader(data_list, batch_size=batch_size, shuffle=False, num_workers=num_workers)\n",
    "\n",
    "    prob_sum = np.zeros(len(files), dtype=np.float64)\n",
    "\n",
    "    for k, ckpt in enumerate(ckpt_paths):\n",
    "        model = model_ctor().to(device)\n",
    "        model = load_state_dict_into(model, ckpt)\n",
    "        model.eval()\n",
    "\n",
    "        idx = 0\n",
    "        for batch in loader:\n",
    "            batch = batch.to(device)\n",
    "\n",
    "            if isinstance(model, GAT):\n",
    "                out = model(batch.x, batch.edge_index, batch.edge_attr, batch.batch)\n",
    "            else:\n",
    "                out = model(batch)\n",
    "\n",
    "            logits = out[0] if isinstance(out, (tuple, list)) else out\n",
    "            logits = logits.view(-1)\n",
    "\n",
    "            probs = torch.sigmoid(logits).detach().cpu().numpy()\n",
    "\n",
    "            bsz = len(probs)\n",
    "            prob_sum[idx:idx+bsz] += probs\n",
    "            idx += bsz\n",
    "\n",
    "        print(f\"  submodel {k+1}/{len(ckpt_paths)} done: {os.path.basename(ckpt)}\")\n",
    "\n",
    "    prob_avg = prob_sum / float(len(ckpt_paths))\n",
    "\n",
    "    return [\n",
    "        {\"file\": os.path.basename(fp), \"path\": fp, \"prob\": float(prob_avg[i])}\n",
    "        for i, fp in enumerate(files)\n",
    "    ]\n",
    "\n",
    "@torch.no_grad()\n",
    "def multi_experiment_predict_probs_graph(\n",
    "    model_ctor,\n",
    "    gat_bool: bool,\n",
    "    ckpt_groups: list[list[str]],   # len=5, each is list of ckpts for that experiment\n",
    "    files: list[str],\n",
    "    batch_size: int = 16,\n",
    "    num_workers: int = 0,\n",
    "    return_std: bool = True,\n",
    ") -> list[dict]:\n",
    "    \"\"\"\n",
    "    For each experiment:\n",
    "      - average probs across that experiment's submodels (your current ensemble)\n",
    "    Then:\n",
    "      - average across experiments (and optionally std across experiments)\n",
    "\n",
    "    Returns rows: {file, path, prob, prob_std(optional)}\n",
    "    \"\"\"\n",
    "    if len(files) == 0:\n",
    "        return []\n",
    "\n",
    "    # We'll store experiment-level predicted probs [n_exps, n_files]\n",
    "    exp_probs = []\n",
    "\n",
    "    for exp_i, ckpt_paths in enumerate(ckpt_groups, start=1):\n",
    "        print(f\"\\n[EXP {exp_i}/{len(ckpt_groups)}] {len(ckpt_paths)} submodels\")\n",
    "        rows = ensemble_predict_probs_graph(\n",
    "            model_ctor=model_ctor,\n",
    "            gat_bool=gat_bool,\n",
    "            ckpt_paths=ckpt_paths,\n",
    "            files=files,\n",
    "            batch_size=batch_size,\n",
    "            num_workers=num_workers,\n",
    "        )\n",
    "        exp_probs.append(np.array([r[\"prob\"] for r in rows], dtype=np.float64))\n",
    "\n",
    "    exp_probs = np.stack(exp_probs, axis=0)  # [n_exps, n_files]\n",
    "    mean_probs = exp_probs.mean(axis=0)\n",
    "\n",
    "    if return_std:\n",
    "        std_probs = exp_probs.std(axis=0, ddof=0)\n",
    "    else:\n",
    "        std_probs = None\n",
    "\n",
    "    out = []\n",
    "    for i, fp in enumerate(files):\n",
    "        row = {\"file\": os.path.basename(fp), \"path\": fp, \"prob\": float(mean_probs[i])}\n",
    "        if std_probs is not None:\n",
    "            row[\"prob_std\"] = float(std_probs[i])\n",
    "        out.append(row)\n",
    "\n",
    "    return out\n",
    "\n",
    "@torch.no_grad()\n",
    "def multi_experiment_predict_probs_cnn2d(\n",
    "    ckpt_groups: list[list[str]],   # len=5\n",
    "    files: list[str],\n",
    "    batch_size: int = 32,\n",
    "    cnn_h: int = 200,\n",
    "    cnn_w: int = 65,\n",
    "    return_std: bool = True,\n",
    ") -> list[dict]:\n",
    "    \"\"\"\n",
    "    Same idea as graph wrapper:\n",
    "      - avg across submodels within each experiment\n",
    "      - then avg across experiments (optionally std)\n",
    "    \"\"\"\n",
    "    if len(files) == 0:\n",
    "        return []\n",
    "\n",
    "    exp_probs = []\n",
    "    for exp_i, ckpt_paths in enumerate(ckpt_groups, start=1):\n",
    "        print(f\"\\n[EXP {exp_i}/{len(ckpt_groups)}] {len(ckpt_paths)} submodels\")\n",
    "        rows = ensemble_predict_probs_cnn2d(\n",
    "            ckpt_paths=ckpt_paths,\n",
    "            files=files,\n",
    "            batch_size=batch_size,\n",
    "            cnn_h=cnn_h,\n",
    "            cnn_w=cnn_w,\n",
    "        )\n",
    "        exp_probs.append(np.array([r[\"prob\"] for r in rows], dtype=np.float64))\n",
    "\n",
    "    exp_probs = np.stack(exp_probs, axis=0)  # [n_exps, n_files]\n",
    "    mean_probs = exp_probs.mean(axis=0)\n",
    "\n",
    "    if return_std:\n",
    "        std_probs = exp_probs.std(axis=0, ddof=0)\n",
    "    else:\n",
    "        std_probs = None\n",
    "\n",
    "    out = []\n",
    "    for i, fp in enumerate(files):\n",
    "        row = {\"file\": os.path.basename(fp), \"path\": fp, \"prob\": float(mean_probs[i])}\n",
    "        if std_probs is not None:\n",
    "            row[\"prob_std\"] = float(std_probs[i])\n",
    "        out.append(row)\n",
    "\n",
    "    return out\n",
    "\n",
    "# -----------------------------\n",
    "# Ensemble inference (CNN2D)\n",
    "# -----------------------------\n",
    "def encoded_matrix_to_cnn_input(encoded_matrix: np.ndarray, cnn_h: int, cnn_w: int) -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    MUST match how you trained CNN2D.\n",
    "\n",
    "    Here we assume 1-channel images of shape (cnn_h, cnn_w).\n",
    "    We reshape only if total size matches.\n",
    "    \"\"\"\n",
    "    if encoded_matrix.ndim != 2:\n",
    "        raise ValueError(f\"encoded_matrix must be 2D, got shape {encoded_matrix.shape}\")\n",
    "\n",
    "    img = encoded_matrix\n",
    "    if img.shape != (cnn_h, cnn_w):\n",
    "        if img.size != cnn_h * cnn_w:\n",
    "            raise ValueError(\n",
    "                f\"encoded_matrix shape {img.shape} (size={img.size}) cannot reshape to ({cnn_h},{cnn_w}). \"\n",
    "                f\"Update cnn_h/cnn_w to your training shape.\"\n",
    "            )\n",
    "        img = img.reshape(cnn_h, cnn_w)\n",
    "\n",
    "    return torch.tensor(img, dtype=torch.float32).unsqueeze(0)  # [C=1,H,W]\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def ensemble_predict_probs_cnn2d(\n",
    "    ckpt_paths: list[str],\n",
    "    files: list[str],\n",
    "    batch_size: int = 32,\n",
    "    cnn_h: int = 200,\n",
    "    cnn_w: int = 65,\n",
    ") -> list[dict]:\n",
    "    \"\"\"\n",
    "    Averages PROBABILITIES across CNN2D submodels.\n",
    "    \"\"\"\n",
    "    if len(files) == 0:\n",
    "        return []\n",
    "\n",
    "    prob_sum = np.zeros(len(files), dtype=np.float64)\n",
    "\n",
    "    for k, ckpt in enumerate(ckpt_paths):\n",
    "        model = CNN2D(input_channels=1).to(device)\n",
    "        model = load_state_dict_into(model, ckpt)\n",
    "        model.eval()\n",
    "\n",
    "        for i in range(0, len(files), batch_size):\n",
    "            batch_files = files[i:i+batch_size]\n",
    "            xs = []\n",
    "            for fp in batch_files:\n",
    "                enc = load_cnn_matrix(fp)\n",
    "                xs.append(encoded_matrix_to_cnn_input(enc, cnn_h=cnn_h, cnn_w=cnn_w))\n",
    "            x_batch = torch.stack(xs, dim=0).to(device)  # [B,1,H,W]\n",
    "\n",
    "            logits = model(x_batch).view(-1)\n",
    "            probs = torch.sigmoid(logits).detach().cpu().numpy()\n",
    "            prob_sum[i:i+len(probs)] += probs\n",
    "\n",
    "        print(f\"  submodel {k+1}/{len(ckpt_paths)} done: {os.path.basename(ckpt)}\")\n",
    "\n",
    "    prob_avg = prob_sum / float(len(ckpt_paths))\n",
    "    rows = []\n",
    "    for i, fp in enumerate(files):\n",
    "        rows.append({\n",
    "            \"file\": os.path.basename(fp),\n",
    "            \"path\": fp,\n",
    "            \"prob\": float(prob_avg[i]),\n",
    "        })\n",
    "    return rows\n",
    "\n",
    "# -----------------------------\n",
    "# Run PU eval for a given ensemble\n",
    "# -----------------------------\n",
    "def run_pu_eval_ensemble(\n",
    "    model_name: str,\n",
    "    out_dir: str,\n",
    "    spies_dir: str,\n",
    "    eval_dir: str,\n",
    "    predict_rows_fn,     # function(files)->rows\n",
    "):\n",
    "    ensure_dir(out_dir)\n",
    "\n",
    "    spy_files = list_npy_files(spies_dir)\n",
    "    eval_files = list_npy_files(eval_dir)\n",
    "\n",
    "    if len(spy_files) == 0:\n",
    "        raise FileNotFoundError(f\"[{model_name}] no spies in {spies_dir}\")\n",
    "    if len(eval_files) == 0:\n",
    "        raise FileNotFoundError(f\"[{model_name}] no eval files in {eval_dir}\")\n",
    "\n",
    "    print(f\"\\n[{model_name}] Predicting spies ({len(spy_files)}) ...\")\n",
    "    spy_rows = predict_rows_fn(spy_files)\n",
    "    spy_probs = np.array([r[\"prob\"] for r in spy_rows], dtype=float)\n",
    "\n",
    "    spy_stats = compute_spy_percentiles(spy_probs)\n",
    "    spy_stats[\"model\"] = model_name\n",
    "    spy_stats[\"spies_dir\"] = spies_dir\n",
    "\n",
    "    # save spies stats + spies probs\n",
    "    with open(os.path.join(out_dir, f\"{model_name}_spies_stats.json\"), \"w\") as f:\n",
    "        json.dump(spy_stats, f, indent=2)\n",
    "    pd.DataFrame([spy_stats]).to_csv(os.path.join(out_dir, f\"{model_name}_spies_stats.csv\"), index=False)\n",
    "    pd.DataFrame(spy_rows).to_csv(os.path.join(out_dir, f\"{model_name}_spies_probs.csv\"), index=False)\n",
    "\n",
    "    print(f\"[{model_name}] spies thresholds: p25={spy_stats['p25']:.4f}, p50={spy_stats['p50']:.4f}, p75={spy_stats['p75']:.4f}\")\n",
    "\n",
    "    print(f\"\\n[{model_name}] Predicting eval dir ({len(eval_files)}) ...\")\n",
    "    eval_rows = predict_rows_fn(eval_files)\n",
    "\n",
    "    # label using spies thresholds\n",
    "    for r in eval_rows:\n",
    "        r[\"label\"] = label_from_percentiles(r[\"prob\"], spy_stats)\n",
    "\n",
    "    df_eval = pd.DataFrame(eval_rows)\n",
    "    out_csv = os.path.join(out_dir, f\"{model_name}_eval_probs_and_labels.csv\")\n",
    "    df_eval.to_csv(out_csv, index=False)\n",
    "\n",
    "    out_png = os.path.join(out_dir, f\"{model_name}_eval_label_hist.png\")\n",
    "    plot_label_histogram(df_eval, f\"{model_name} label counts (ensemble avg; thresholds from spies)\", out_png)\n",
    "\n",
    "    print(f\"\\n[{model_name}] label counts:\\n{df_eval['label'].value_counts()}\")\n",
    "    print(f\"Saved: {out_csv}\")\n",
    "    print(f\"Saved: {out_png}\")\n",
    "    print(f\"Saved: {os.path.join(out_dir, f'{model_name}_spies_stats.json')}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "481a7d50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GAT experiments: [50, 50, 50, 50, 50]\n",
      "GCN experiments: [50, 50, 50, 50, 50]\n",
      "CNN2D experiments: [50, 50, 50, 50, 50]\n",
      "CNN3D experiments: [50, 50]\n",
      "\n",
      "[CNN3D_ENSEMBLE] EXP 1/2: spies=770 eval=75\n",
      "  submodel 1/50 done: model_bin_1.pth\n",
      "  submodel 2/50 done: model_bin_10.pth\n",
      "  submodel 3/50 done: model_bin_11.pth\n",
      "  submodel 4/50 done: model_bin_12.pth\n",
      "  submodel 5/50 done: model_bin_13.pth\n",
      "  submodel 6/50 done: model_bin_14.pth\n",
      "  submodel 7/50 done: model_bin_15.pth\n",
      "  submodel 8/50 done: model_bin_16.pth\n",
      "  submodel 9/50 done: model_bin_17.pth\n",
      "  submodel 10/50 done: model_bin_18.pth\n",
      "  submodel 11/50 done: model_bin_19.pth\n",
      "  submodel 12/50 done: model_bin_2.pth\n",
      "  submodel 13/50 done: model_bin_20.pth\n",
      "  submodel 14/50 done: model_bin_21.pth\n",
      "  submodel 15/50 done: model_bin_22.pth\n",
      "  submodel 16/50 done: model_bin_23.pth\n",
      "  submodel 17/50 done: model_bin_24.pth\n",
      "  submodel 18/50 done: model_bin_25.pth\n",
      "  submodel 19/50 done: model_bin_26.pth\n",
      "  submodel 20/50 done: model_bin_27.pth\n",
      "  submodel 21/50 done: model_bin_28.pth\n",
      "  submodel 22/50 done: model_bin_29.pth\n",
      "  submodel 23/50 done: model_bin_3.pth\n",
      "  submodel 24/50 done: model_bin_30.pth\n",
      "  submodel 25/50 done: model_bin_31.pth\n",
      "  submodel 26/50 done: model_bin_32.pth\n",
      "  submodel 27/50 done: model_bin_33.pth\n",
      "  submodel 28/50 done: model_bin_34.pth\n",
      "  submodel 29/50 done: model_bin_35.pth\n",
      "  submodel 30/50 done: model_bin_36.pth\n",
      "  submodel 31/50 done: model_bin_37.pth\n",
      "  submodel 32/50 done: model_bin_38.pth\n",
      "  submodel 33/50 done: model_bin_39.pth\n",
      "  submodel 34/50 done: model_bin_4.pth\n",
      "  submodel 35/50 done: model_bin_40.pth\n",
      "  submodel 36/50 done: model_bin_41.pth\n",
      "  submodel 37/50 done: model_bin_42.pth\n",
      "  submodel 38/50 done: model_bin_43.pth\n",
      "  submodel 39/50 done: model_bin_44.pth\n",
      "  submodel 40/50 done: model_bin_45.pth\n",
      "  submodel 41/50 done: model_bin_46.pth\n",
      "  submodel 42/50 done: model_bin_47.pth\n",
      "  submodel 43/50 done: model_bin_48.pth\n",
      "  submodel 44/50 done: model_bin_49.pth\n",
      "  submodel 45/50 done: model_bin_5.pth\n",
      "  submodel 46/50 done: model_bin_50.pth\n",
      "  submodel 47/50 done: model_bin_6.pth\n",
      "  submodel 48/50 done: model_bin_7.pth\n",
      "  submodel 49/50 done: model_bin_8.pth\n",
      "  submodel 50/50 done: model_bin_9.pth\n",
      "  submodel 1/50 done: model_bin_1.pth\n",
      "  submodel 2/50 done: model_bin_10.pth\n",
      "  submodel 3/50 done: model_bin_11.pth\n",
      "  submodel 4/50 done: model_bin_12.pth\n",
      "  submodel 5/50 done: model_bin_13.pth\n",
      "  submodel 6/50 done: model_bin_14.pth\n",
      "  submodel 7/50 done: model_bin_15.pth\n",
      "  submodel 8/50 done: model_bin_16.pth\n",
      "  submodel 9/50 done: model_bin_17.pth\n",
      "  submodel 10/50 done: model_bin_18.pth\n",
      "  submodel 11/50 done: model_bin_19.pth\n",
      "  submodel 12/50 done: model_bin_2.pth\n",
      "  submodel 13/50 done: model_bin_20.pth\n",
      "  submodel 14/50 done: model_bin_21.pth\n",
      "  submodel 15/50 done: model_bin_22.pth\n",
      "  submodel 16/50 done: model_bin_23.pth\n",
      "  submodel 17/50 done: model_bin_24.pth\n",
      "  submodel 18/50 done: model_bin_25.pth\n",
      "  submodel 19/50 done: model_bin_26.pth\n",
      "  submodel 20/50 done: model_bin_27.pth\n",
      "  submodel 21/50 done: model_bin_28.pth\n",
      "  submodel 22/50 done: model_bin_29.pth\n",
      "  submodel 23/50 done: model_bin_3.pth\n",
      "  submodel 24/50 done: model_bin_30.pth\n",
      "  submodel 25/50 done: model_bin_31.pth\n",
      "  submodel 26/50 done: model_bin_32.pth\n",
      "  submodel 27/50 done: model_bin_33.pth\n",
      "  submodel 28/50 done: model_bin_34.pth\n",
      "  submodel 29/50 done: model_bin_35.pth\n",
      "  submodel 30/50 done: model_bin_36.pth\n",
      "  submodel 31/50 done: model_bin_37.pth\n",
      "  submodel 32/50 done: model_bin_38.pth\n",
      "  submodel 33/50 done: model_bin_39.pth\n",
      "  submodel 34/50 done: model_bin_4.pth\n",
      "  submodel 35/50 done: model_bin_40.pth\n",
      "  submodel 36/50 done: model_bin_41.pth\n",
      "  submodel 37/50 done: model_bin_42.pth\n",
      "  submodel 38/50 done: model_bin_43.pth\n",
      "  submodel 39/50 done: model_bin_44.pth\n",
      "  submodel 40/50 done: model_bin_45.pth\n",
      "  submodel 41/50 done: model_bin_46.pth\n",
      "  submodel 42/50 done: model_bin_47.pth\n",
      "  submodel 43/50 done: model_bin_48.pth\n",
      "  submodel 44/50 done: model_bin_49.pth\n",
      "  submodel 45/50 done: model_bin_5.pth\n",
      "  submodel 46/50 done: model_bin_50.pth\n",
      "  submodel 47/50 done: model_bin_6.pth\n",
      "  submodel 48/50 done: model_bin_7.pth\n",
      "  submodel 49/50 done: model_bin_8.pth\n",
      "  submodel 50/50 done: model_bin_9.pth\n",
      "  thresholds: p25=0.9941, p50=0.9989, p75=0.9995\n",
      "\n",
      "[CNN3D_ENSEMBLE] EXP 2/2: spies=770 eval=75\n",
      "  submodel 1/50 done: model_bin_1.pth\n",
      "  submodel 2/50 done: model_bin_10.pth\n",
      "  submodel 3/50 done: model_bin_11.pth\n",
      "  submodel 4/50 done: model_bin_12.pth\n",
      "  submodel 5/50 done: model_bin_13.pth\n",
      "  submodel 6/50 done: model_bin_14.pth\n",
      "  submodel 7/50 done: model_bin_15.pth\n",
      "  submodel 8/50 done: model_bin_16.pth\n",
      "  submodel 9/50 done: model_bin_17.pth\n",
      "  submodel 10/50 done: model_bin_18.pth\n",
      "  submodel 11/50 done: model_bin_19.pth\n",
      "  submodel 12/50 done: model_bin_2.pth\n",
      "  submodel 13/50 done: model_bin_20.pth\n",
      "  submodel 14/50 done: model_bin_21.pth\n",
      "  submodel 15/50 done: model_bin_22.pth\n",
      "  submodel 16/50 done: model_bin_23.pth\n",
      "  submodel 17/50 done: model_bin_24.pth\n",
      "  submodel 18/50 done: model_bin_25.pth\n",
      "  submodel 19/50 done: model_bin_26.pth\n",
      "  submodel 20/50 done: model_bin_27.pth\n",
      "  submodel 21/50 done: model_bin_28.pth\n",
      "  submodel 22/50 done: model_bin_29.pth\n",
      "  submodel 23/50 done: model_bin_3.pth\n",
      "  submodel 24/50 done: model_bin_30.pth\n",
      "  submodel 25/50 done: model_bin_31.pth\n",
      "  submodel 26/50 done: model_bin_32.pth\n",
      "  submodel 27/50 done: model_bin_33.pth\n",
      "  submodel 28/50 done: model_bin_34.pth\n",
      "  submodel 29/50 done: model_bin_35.pth\n",
      "  submodel 30/50 done: model_bin_36.pth\n",
      "  submodel 31/50 done: model_bin_37.pth\n",
      "  submodel 32/50 done: model_bin_38.pth\n",
      "  submodel 33/50 done: model_bin_39.pth\n",
      "  submodel 34/50 done: model_bin_4.pth\n",
      "  submodel 35/50 done: model_bin_40.pth\n",
      "  submodel 36/50 done: model_bin_41.pth\n",
      "  submodel 37/50 done: model_bin_42.pth\n",
      "  submodel 38/50 done: model_bin_43.pth\n",
      "  submodel 39/50 done: model_bin_44.pth\n",
      "  submodel 40/50 done: model_bin_45.pth\n",
      "  submodel 41/50 done: model_bin_46.pth\n",
      "  submodel 42/50 done: model_bin_47.pth\n",
      "  submodel 43/50 done: model_bin_48.pth\n",
      "  submodel 44/50 done: model_bin_49.pth\n",
      "  submodel 45/50 done: model_bin_5.pth\n",
      "  submodel 46/50 done: model_bin_50.pth\n",
      "  submodel 47/50 done: model_bin_6.pth\n",
      "  submodel 48/50 done: model_bin_7.pth\n",
      "  submodel 49/50 done: model_bin_8.pth\n",
      "  submodel 50/50 done: model_bin_9.pth\n",
      "  submodel 1/50 done: model_bin_1.pth\n",
      "  submodel 2/50 done: model_bin_10.pth\n",
      "  submodel 3/50 done: model_bin_11.pth\n",
      "  submodel 4/50 done: model_bin_12.pth\n",
      "  submodel 5/50 done: model_bin_13.pth\n",
      "  submodel 6/50 done: model_bin_14.pth\n",
      "  submodel 7/50 done: model_bin_15.pth\n",
      "  submodel 8/50 done: model_bin_16.pth\n",
      "  submodel 9/50 done: model_bin_17.pth\n",
      "  submodel 10/50 done: model_bin_18.pth\n",
      "  submodel 11/50 done: model_bin_19.pth\n",
      "  submodel 12/50 done: model_bin_2.pth\n",
      "  submodel 13/50 done: model_bin_20.pth\n",
      "  submodel 14/50 done: model_bin_21.pth\n",
      "  submodel 15/50 done: model_bin_22.pth\n",
      "  submodel 16/50 done: model_bin_23.pth\n",
      "  submodel 17/50 done: model_bin_24.pth\n",
      "  submodel 18/50 done: model_bin_25.pth\n",
      "  submodel 19/50 done: model_bin_26.pth\n",
      "  submodel 20/50 done: model_bin_27.pth\n",
      "  submodel 21/50 done: model_bin_28.pth\n",
      "  submodel 22/50 done: model_bin_29.pth\n",
      "  submodel 23/50 done: model_bin_3.pth\n",
      "  submodel 24/50 done: model_bin_30.pth\n",
      "  submodel 25/50 done: model_bin_31.pth\n",
      "  submodel 26/50 done: model_bin_32.pth\n",
      "  submodel 27/50 done: model_bin_33.pth\n",
      "  submodel 28/50 done: model_bin_34.pth\n",
      "  submodel 29/50 done: model_bin_35.pth\n",
      "  submodel 30/50 done: model_bin_36.pth\n",
      "  submodel 31/50 done: model_bin_37.pth\n",
      "  submodel 32/50 done: model_bin_38.pth\n",
      "  submodel 33/50 done: model_bin_39.pth\n",
      "  submodel 34/50 done: model_bin_4.pth\n",
      "  submodel 35/50 done: model_bin_40.pth\n",
      "  submodel 36/50 done: model_bin_41.pth\n",
      "  submodel 37/50 done: model_bin_42.pth\n",
      "  submodel 38/50 done: model_bin_43.pth\n",
      "  submodel 39/50 done: model_bin_44.pth\n",
      "  submodel 40/50 done: model_bin_45.pth\n",
      "  submodel 41/50 done: model_bin_46.pth\n",
      "  submodel 42/50 done: model_bin_47.pth\n",
      "  submodel 43/50 done: model_bin_48.pth\n",
      "  submodel 44/50 done: model_bin_49.pth\n",
      "  submodel 45/50 done: model_bin_5.pth\n",
      "  submodel 46/50 done: model_bin_50.pth\n",
      "  submodel 47/50 done: model_bin_6.pth\n",
      "  submodel 48/50 done: model_bin_7.pth\n",
      "  submodel 49/50 done: model_bin_8.pth\n",
      "  submodel 50/50 done: model_bin_9.pth\n",
      "  thresholds: p25=0.9918, p50=0.9984, p75=0.9994\n",
      "\n",
      "[CNN3D_ENSEMBLE] majority label counts:\n",
      "label\n",
      "Positive          41\n",
      "PseudoPositive    19\n",
      "PseudoNegative    10\n",
      "Negative           5\n",
      "Name: count, dtype: int64\n",
      "Saved: ./PU_EvalOutputs_Ensemble/CNN3D_2_exp_total_grid_sep/CNN3D_ENSEMBLE_eval_probs_and_labels.csv\n",
      "Saved: ./PU_EvalOutputs_Ensemble/CNN3D_2_exp_total_grid_sep/CNN3D_ENSEMBLE_eval_label_hist_5exp.png\n",
      "Saved: ./PU_EvalOutputs_Ensemble/CNN3D_2_exp_total_grid_sep/CNN3D_ENSEMBLE_spies_stats_5exp.json\n"
     ]
    }
   ],
   "source": [
    "# Each entry = one experiment's checkpoints (submodels)\n",
    "GAT_EXPS = [\n",
    "    \"../CLR_Ligand_Training/GAT-CLR_Exp1/Models/*.pth\",\n",
    "    \"../CLR_Ligand_Training/GAT-CLR_Exp2/Models/*.pth\",\n",
    "    \"../CLR_Ligand_Training/GAT-CLR_Exp3/Models/*.pth\",\n",
    "    \"../CLR_Ligand_Training/GAT-CLR_Exp4/Models/*.pth\",\n",
    "    \"../CLR_Ligand_Training/GAT-CLR_Exp5/Models/*.pth\",\n",
    "]\n",
    "\n",
    "GCN_EXPS = [\n",
    "    \"../CLR_Ligand_Training/GCN-CLR_Exp1/*.pth\",\n",
    "    \"../CLR_Ligand_Training/GCN-CLR_Exp2/*.pth\",\n",
    "    \"../CLR_Ligand_Training/GCN-CLR_Exp3/*.pth\",\n",
    "    \"../CLR_Ligand_Training/GCN-CLR_Exp4/*.pth\",\n",
    "    \"../CLR_Ligand_Training/GCN-CLR_Exp5/*.pth\",\n",
    "]\n",
    "\n",
    "CNN2D_EXPS = [\n",
    "    \"../CLR_Ligand_Training/GNN-CLR_Exp1/*.pth\",\n",
    "    \"../CLR_Ligand_Training/GNN-CLR_Exp2/*.pth\",\n",
    "    \"../CLR_Ligand_Training/GNN-CLR_Exp3/*.pth\",\n",
    "    \"../CLR_Ligand_Training/GNN-CLR_Exp4/*.pth\",\n",
    "    \"../CLR_Ligand_Training/GNN-CLR_Exp5/*.pth\",\n",
    "]\n",
    "\n",
    "CNN3D_EXPS = [\n",
    "    \"../CLR_Ligand_Training/3DCNN-CLR_Exp1/*.pth\",\n",
    "    \"../CLR_Ligand_Training/3DCNN-CLR_Exp2/*.pth\"\n",
    "]\n",
    "\n",
    "gat_ckpt_groups = [resolve_ensemble_checkpoints(p) for p in GAT_EXPS]\n",
    "gcn_ckpt_groups = [resolve_ensemble_checkpoints(p) for p in GCN_EXPS]\n",
    "cnn_ckpt_groups = [resolve_ensemble_checkpoints(p) for p in CNN2D_EXPS]\n",
    "cnn3d_ckpt_groups = [resolve_ensemble_checkpoints(p) for p in CNN3D_EXPS]\n",
    "\n",
    "print(\"GAT experiments:\", [len(g) for g in gat_ckpt_groups])\n",
    "print(\"GCN experiments:\", [len(g) for g in gcn_ckpt_groups])\n",
    "print(\"CNN2D experiments:\", [len(g) for g in cnn_ckpt_groups])\n",
    "print(\"CNN3D experiments:\", [len(g) for g in cnn3d_ckpt_groups])\n",
    "\n",
    "GRAPH_INPUT_DIM = infer_graph_input_dim(gat_gcn_spies_exps[0])\n",
    "\n",
    "def make_gat():\n",
    "    return GAT(in_channels=GRAPH_INPUT_DIM, out_channels=32, dropout_p=0.1)\n",
    "\n",
    "def make_gcn():\n",
    "    return GCN(input_dim=GRAPH_INPUT_DIM)\n",
    "\n",
    "# run_pu_eval_5exp_with_exp_spies(\n",
    "#     model_name=\"GAT_ENSEMBLE\",\n",
    "#     out_dir=os.path.join(OUT_ROOT, \"GAT_5_exp_separate_graphs_sep\"),\n",
    "#     spies_dirs=gat_gcn_spies_exps,\n",
    "#     eval_dir=gat_gcn_unlabeled,\n",
    "#     predict_rows_fn_per_exp=lambda files, exp_idx: ensemble_predict_probs_graph(\n",
    "#         model_ctor=make_gat,\n",
    "#         gat_bool=True,\n",
    "#         ckpt_paths=gat_ckpt_groups[exp_idx],   # <-- exp-specific ckpts\n",
    "#         files=files,\n",
    "#         batch_size=16,\n",
    "#     ),\n",
    "# )\n",
    "\n",
    "# run_pu_eval_5exp_with_exp_spies(\n",
    "#     model_name=\"GCN_ENSEMBLE\",\n",
    "#     out_dir=os.path.join(OUT_ROOT, \"GCN_5_exp_separate_graphs_sep\"),\n",
    "#     spies_dirs=gat_gcn_spies_exps,\n",
    "#     eval_dir=gat_gcn_unlabeled,\n",
    "#     predict_rows_fn_per_exp=lambda files, exp_idx: ensemble_predict_probs_graph(\n",
    "#         model_ctor=make_gcn,\n",
    "#         gat_bool=False,\n",
    "#         ckpt_paths=gcn_ckpt_groups[exp_idx],   # <-- exp-specific ckpts\n",
    "#         files=files,\n",
    "#         batch_size=16,\n",
    "#     ),\n",
    "# )\n",
    "\n",
    "# run_pu_eval_5exp_with_exp_spies(\n",
    "#     model_name=\"CNN2D_ENSEMBLE\",\n",
    "#     out_dir=os.path.join(OUT_ROOT, \"CNN2D_5_exp_graph_format_sep\"),\n",
    "#     spies_dirs=gnn_spies_exps,\n",
    "#     eval_dir=gnn_unlabeled,\n",
    "#     predict_rows_fn_per_exp=lambda files, exp_idx: ensemble_predict_probs_cnn2d(\n",
    "#         ckpt_paths=cnn_ckpt_groups[exp_idx],  # <-- exp-specific ckpts\n",
    "#         files=files,\n",
    "#         batch_size=32,\n",
    "#         cnn_h=200,\n",
    "#         cnn_w=65,\n",
    "#     ),\n",
    "# )\n",
    "\n",
    "run_pu_eval_5exp_with_exp_spies(\n",
    "    model_name=\"CNN3D_ENSEMBLE\",\n",
    "    out_dir=os.path.join(OUT_ROOT, \"CNN3D_2_exp_total_grid_sep\"),\n",
    "    spies_dirs=cnn_spies_exps,          # <-- 3D CNN spies should match grid-format experiments\n",
    "    eval_dir=cnn_unlabeled,             # <-- IMPORTANT: this must point to your 3D GRID unlabeled dir\n",
    "    predict_rows_fn_per_exp=lambda files, exp_idx: ensemble_predict_probs_cnn3d(\n",
    "        ckpt_paths=cnn3d_ckpt_groups[exp_idx],\n",
    "        files=files,\n",
    "        batch_size=8,\n",
    "    ),\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f6c69e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# =========================\n",
    "# Config\n",
    "# =========================\n",
    "BASE = Path(\".\")\n",
    "\n",
    "# 1_16 results\n",
    "MODEL_FILES_1_16 = {\n",
    "    \"GNN\": BASE / \"PU_EvalOutputs_Ensemble/1_16_results/CNN2D_5_exp_graph_format_1_16/CNN2D_ENSEMBLE_eval_probs_and_labels.csv\",\n",
    "    \"GAT\": BASE / \"PU_EvalOutputs_Ensemble/1_16_results/GAT_5_exp_separate_graphs_1_16/GAT_ENSEMBLE_eval_probs_and_labels.csv\",\n",
    "    \"GCN\": BASE / \"PU_EvalOutputs_Ensemble/1_16_results/GCN_5_exp_separate_graphs_1_16/GCN_ENSEMBLE_eval_probs_and_labels.csv\",\n",
    "}\n",
    "OCC_PREFIX_1_16 = \"1_16-piezo-graph-5A\"\n",
    "\n",
    "# sep results\n",
    "MODEL_FILES_SEP = {\n",
    "    \"GNN\": BASE / \"PU_EvalOutputs_Ensemble/sep_results/CNN2D_5_exp_graph_format_sep/CNN2D_ENSEMBLE_eval_probs_and_labels.csv\",\n",
    "    \"GAT\": BASE / \"PU_EvalOutputs_Ensemble/sep_results/GAT_5_exp_separate_graphs_sep/GAT_ENSEMBLE_eval_probs_and_labels.csv\",\n",
    "    \"GCN\": BASE / \"PU_EvalOutputs_Ensemble/sep_results/GCN_5_exp_separate_graphs_sep/GCN_ENSEMBLE_eval_probs_and_labels.csv\",\n",
    "}\n",
    "OCC_PREFIX_SEP = \"separate-piezo-graph-5A\"\n",
    "\n",
    "# anton results (NEW)\n",
    "MODEL_FILES_ANTON = {\n",
    "    \"GNN\": BASE / \"PU_EvalOutputs_Ensemble/anton_results/CNN2D_5_exp_graph_format_anton/CNN2D_ENSEMBLE_eval_probs_and_labels.csv\",\n",
    "    \"GAT\": BASE / \"PU_EvalOutputs_Ensemble/anton_results/GAT_5_exp_separate_graphs_anton/GAT_ENSEMBLE_eval_probs_and_labels.csv\",\n",
    "    \"GCN\": BASE / \"PU_EvalOutputs_Ensemble/anton_results/GCN_5_exp_separate_graphs_anton/GCN_ENSEMBLE_eval_probs_and_labels.csv\",\n",
    "}\n",
    "OCC_PREFIX_ANTON = \"anton-piezo-graph-5A\"\n",
    "\n",
    "OCC_FILE = BASE / \"Alex_MD_data.csv\"\n",
    "\n",
    "# =========================\n",
    "# Dynamic binning config\n",
    "# =========================\n",
    "XTICKS = np.array([0, 20, 40, 60, 80, 100])\n",
    "\n",
    "BINNING_MODE = \"quantile\"   # \"quantile\" or \"equal_width\"\n",
    "N_BINS = 8                  # increase this for more bins (e.g., 6, 8, 10, 12)\n",
    "\n",
    "# Limit binning to this occupancy range (useful if you want to ignore extreme tails)\n",
    "BIN_RANGE = (0.0, 100.0)    # (min, max)\n",
    "\n",
    "\n",
    "# =========================\n",
    "# Helpers\n",
    "# =========================\n",
    "def make_global_id(dataset_label: str, local_id: str) -> str:\n",
    "    return f\"{dataset_label}::{local_id}\"\n",
    "\n",
    "def extract_id_from_eval_row(file_val: str, path_val: str) -> str | None:\n",
    "    s_file = str(file_val)\n",
    "    s_path = str(path_val)\n",
    "\n",
    "    # 1_16 / sep: \"2828_graphs.npy\" -> \"2828\"\n",
    "    m = re.match(r\"(\\d{4})\", s_file)\n",
    "    if m:\n",
    "        return m.group(1)\n",
    "\n",
    "    # anton: want \"box13_mode8\" etc (try file first)\n",
    "    m = re.search(r\"(box\\d+).*?(?:mode[_-]?(\\d+))\", s_file, flags=re.IGNORECASE)\n",
    "    if m:\n",
    "        return f\"{m.group(1).lower()}_mode{m.group(2)}\"\n",
    "\n",
    "    # if file doesn't contain mode, try path\n",
    "    m = re.search(r\"(box\\d+).*?(?:mode[_-]?(\\d+))\", s_path, flags=re.IGNORECASE)\n",
    "    if m:\n",
    "        return f\"{m.group(1).lower()}_mode{m.group(2)}\"\n",
    "\n",
    "    # fallback: sometimes only \"box#\" exists (but this will create collisions)\n",
    "    m = re.search(r\"(box\\d+)\", s_file, flags=re.IGNORECASE)\n",
    "    if m:\n",
    "        return m.group(1).lower()\n",
    "\n",
    "    m = re.search(r\"(box\\d+)\", s_path, flags=re.IGNORECASE)\n",
    "    if m:\n",
    "        return m.group(1).lower()\n",
    "\n",
    "    return None\n",
    "\n",
    "def extract_id_from_occ_filename(dataset_label: str, filename_val: str) -> str | None:\n",
    "    s = str(filename_val)\n",
    "\n",
    "    if dataset_label in (\"1_16\", \"sep\"):\n",
    "        m = re.search(r\"CHL1_(\\d{4})\", s)\n",
    "        return m.group(1) if m else None\n",
    "\n",
    "    if dataset_label == \"anton\":\n",
    "        m = re.search(r\"(box\\d+).*?(?:mode[_-]?(\\d+))\", s, flags=re.IGNORECASE)\n",
    "        if m:\n",
    "            return f\"{m.group(1).lower()}_mode{m.group(2)}\"\n",
    "        return None\n",
    "\n",
    "    return None\n",
    "\n",
    "def load_model_eval_csv(path: Path, dataset_label: str) -> pd.DataFrame:\n",
    "    df = pd.read_csv(path)\n",
    "\n",
    "    local_ids = [\n",
    "        extract_id_from_eval_row(f, p) for f, p in zip(df[\"file\"], df[\"path\"])\n",
    "    ]\n",
    "    df[\"id_key\"] = [\n",
    "        make_global_id(dataset_label, lid) if lid is not None else None\n",
    "        for lid in local_ids\n",
    "    ]\n",
    "\n",
    "    df = df.dropna(subset=[\"id_key\"]).copy()\n",
    "    df[\"prob\"] = pd.to_numeric(df[\"prob\"], errors=\"coerce\")\n",
    "    df = df.dropna(subset=[\"prob\"]).copy()\n",
    "    df[\"dataset\"] = dataset_label\n",
    "    return df\n",
    "\n",
    "def load_occupancy_csv(path: Path, prefixes: list[str]) -> pd.DataFrame:\n",
    "    occ = pd.read_csv(path)\n",
    "\n",
    "    fn = occ[\"filename\"].astype(str)\n",
    "    mask = False\n",
    "    for p in prefixes:\n",
    "        mask = mask | fn.str.startswith(p)\n",
    "    occ = occ[mask].copy()\n",
    "\n",
    "    def dataset_from_prefix(x: str) -> str:\n",
    "        s = str(x)\n",
    "        if s.startswith(OCC_PREFIX_1_16):\n",
    "            return \"1_16\"\n",
    "        if s.startswith(OCC_PREFIX_SEP):\n",
    "            return \"sep\"\n",
    "        if s.startswith(OCC_PREFIX_ANTON):\n",
    "            return \"anton\"\n",
    "        return \"unknown\"\n",
    "\n",
    "    occ[\"occ_dataset\"] = occ[\"filename\"].astype(str).apply(dataset_from_prefix)\n",
    "\n",
    "    local_ids = [\n",
    "        extract_id_from_occ_filename(dataset, fname)\n",
    "        for dataset, fname in zip(occ[\"occ_dataset\"], occ[\"filename\"])\n",
    "    ]\n",
    "    occ[\"id_key\"] = [\n",
    "        make_global_id(dataset, lid) if lid is not None else None\n",
    "        for dataset, lid in zip(occ[\"occ_dataset\"], local_ids)\n",
    "    ]\n",
    "    occ = occ.dropna(subset=[\"id_key\"]).copy()\n",
    "\n",
    "    # numeric columns\n",
    "    for col in [\"high_occupancy\", \"GNN\", \"GAT\", \"GCN\"]:\n",
    "        if col in occ.columns:\n",
    "            occ[col] = pd.to_numeric(occ[col], errors=\"coerce\")\n",
    "\n",
    "    occ = occ.dropna(subset=[\"high_occupancy\"]).copy()\n",
    "\n",
    "    # keep first per id_key\n",
    "    occ = occ.sort_values([\"id_key\", \"occ_dataset\"]).drop_duplicates(\"id_key\", keep=\"first\")\n",
    "\n",
    "    # keep old scores too (if present)\n",
    "    keep_cols = [\"id_key\", \"high_occupancy\", \"occ_dataset\", \"filename\"]\n",
    "    for c in [\"GNN\", \"GAT\", \"GCN\", \"gnn_std\", \"gat_std\", \"gcn_std\"]:\n",
    "        if c in occ.columns:\n",
    "            keep_cols.append(c)\n",
    "\n",
    "    return occ[keep_cols]\n",
    "\n",
    "\n",
    "def compute_dynamic_bins(occ_values: pd.Series, mode: str, n_bins: int, bin_range=(0.0, 100.0)):\n",
    "    \"\"\"\n",
    "    Returns (bin_edges, bin_labels, bin_pos, bin_widths)\n",
    "    Edges live in the same units as high_occupancy.\n",
    "    \"\"\"\n",
    "    v = pd.to_numeric(occ_values, errors=\"coerce\").dropna().astype(float)\n",
    "    v = v.clip(lower=bin_range[0], upper=bin_range[1])\n",
    "\n",
    "    if v.empty:\n",
    "        raise ValueError(\"No occupancy values available to compute bins.\")\n",
    "\n",
    "    if mode == \"quantile\":\n",
    "        qs = np.linspace(0, 1, n_bins + 1)\n",
    "        edges = np.quantile(v, qs)\n",
    "        edges = np.unique(edges)  # remove duplicates if many identical values\n",
    "\n",
    "        # If duplicates collapse bins, fall back to equal-width\n",
    "        if len(edges) < 4:\n",
    "            edges = np.linspace(bin_range[0], bin_range[1], n_bins + 1)\n",
    "\n",
    "    elif mode == \"equal_width\":\n",
    "        edges = np.linspace(bin_range[0], bin_range[1], n_bins + 1)\n",
    "\n",
    "    else:\n",
    "        raise ValueError(f\"Unknown BINNING_MODE: {mode}\")\n",
    "\n",
    "    # Ensure strictly increasing edges\n",
    "    edges = np.array(edges, dtype=float)\n",
    "    edges = np.unique(edges)\n",
    "    if len(edges) < 3:\n",
    "        raise ValueError(\"Computed bin edges collapsed too much. Reduce N_BINS or use equal_width.\")\n",
    "\n",
    "    labels = [f\"{edges[i]:.1f}{edges[i+1]:.1f}\" for i in range(len(edges) - 1)]\n",
    "    pos = (edges[:-1] + edges[1:]) / 2.0\n",
    "    widths = (edges[1:] - edges[:-1])\n",
    "\n",
    "    return edges, labels, pos, widths\n",
    "\n",
    "\n",
    "\n",
    "def assign_bins(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    df = df.copy()\n",
    "    df[\"high_occupancy\"] = df[\"high_occupancy\"].clip(lower=0, upper=100)\n",
    "\n",
    "    df[\"occ_bin\"] = pd.cut(\n",
    "        df[\"high_occupancy\"],\n",
    "        bins=BIN_EDGES,\n",
    "        include_lowest=True,\n",
    "        right=True,\n",
    "        labels=BIN_LABELS\n",
    "    )\n",
    "\n",
    "    df = df.dropna(subset=[\"occ_bin\"]).copy()\n",
    "    df[\"occ_bin\"] = df[\"occ_bin\"].astype(\n",
    "        pd.CategoricalDtype(categories=BIN_LABELS, ordered=True)\n",
    "    )\n",
    "    return df\n",
    "\n",
    "\n",
    "\n",
    "def build_model_dfs(model_files: dict, dataset_label: str, occ: pd.DataFrame) -> dict[str, pd.DataFrame]:\n",
    "    out = {}\n",
    "    for model_name, csv_path in model_files.items():\n",
    "        mdf = load_model_eval_csv(csv_path, dataset_label=dataset_label)\n",
    "        mdf = mdf.merge(occ, on=\"id_key\", how=\"inner\")\n",
    "        mdf = assign_bins(mdf)\n",
    "        out[model_name] = mdf\n",
    "    return out\n",
    "\n",
    "\n",
    "# =========================\n",
    "# Load occupancy (all 3 prefixes)\n",
    "# =========================\n",
    "occ = load_occupancy_csv(\n",
    "    OCC_FILE,\n",
    "    prefixes=[OCC_PREFIX_1_16, OCC_PREFIX_SEP, OCC_PREFIX_ANTON]\n",
    ")\n",
    "\n",
    "# =========================\n",
    "# Compute dynamic bins from OCC values (one time)\n",
    "# =========================\n",
    "BIN_EDGES, BIN_LABELS, BIN_POS, BIN_WIDTHS = compute_dynamic_bins(\n",
    "    occ_values=occ[\"high_occupancy\"],\n",
    "    mode=BINNING_MODE,\n",
    "    n_bins=N_BINS,\n",
    "    bin_range=BIN_RANGE\n",
    ")\n",
    "\n",
    "print(\"\\nDynamic bins:\")\n",
    "for i in range(len(BIN_LABELS)):\n",
    "    print(f\"  Bin {i+1}: {BIN_LABELS[i]}\")\n",
    "\n",
    "\n",
    "# =========================\n",
    "# Load each dataset + merge with occupancy\n",
    "# =========================\n",
    "dfs_1_16 = build_model_dfs(MODEL_FILES_1_16, dataset_label=\"1_16\", occ=occ)\n",
    "dfs_sep  = build_model_dfs(MODEL_FILES_SEP,  dataset_label=\"sep\",  occ=occ)\n",
    "dfs_anton= build_model_dfs(MODEL_FILES_ANTON,dataset_label=\"anton\",occ=occ)\n",
    "\n",
    "# =========================\n",
    "# Combine 1_16 + sep + anton into ONE dataset per model\n",
    "# =========================\n",
    "models_in_order = [\"GNN\", \"GAT\", \"GCN\"]\n",
    "\n",
    "dfs_all = {}\n",
    "for model_name in models_in_order:\n",
    "    dfs_all[model_name] = pd.concat(\n",
    "        [dfs_1_16[model_name], dfs_sep[model_name], dfs_anton[model_name]],\n",
    "        ignore_index=True\n",
    "    )\n",
    "\n",
    "# =========================\n",
    "# Build OLD (from OCC columns) and align to NEW ids\n",
    "# =========================\n",
    "MODEL_TO_OCC_COL = {\"GNN\": \"GNN\", \"GAT\": \"GAT\", \"GCN\": \"GCN\"}\n",
    "\n",
    "dfs_old = {}\n",
    "for model_name in models_in_order:\n",
    "    col = MODEL_TO_OCC_COL[model_name]\n",
    "    if col not in occ.columns:\n",
    "        print(f\"[WARN] OCC column '{col}' not found. Skipping OLD for {model_name}.\")\n",
    "        continue\n",
    "\n",
    "    # keep rows that have an old score for this model\n",
    "    old_df = occ.dropna(subset=[col]).copy()\n",
    "    old_df = old_df.rename(columns={col: \"prob_old\"})\n",
    "    old_df[\"prob_old\"] = pd.to_numeric(old_df[\"prob_old\"], errors=\"coerce\")\n",
    "    old_df = old_df.dropna(subset=[\"prob_old\"]).copy()\n",
    "\n",
    "    # align OLD to the ids that exist in NEW for this model (apples-to-apples)\n",
    "    new_ids = set(dfs_all[model_name][\"id_key\"])\n",
    "    old_df = old_df[old_df[\"id_key\"].isin(new_ids)].copy()\n",
    "\n",
    "    # add bins using same BIN_EDGES/BIN_LABELS\n",
    "    old_df[\"occ_bin\"] = pd.cut(\n",
    "        old_df[\"high_occupancy\"].clip(0, 100),\n",
    "        bins=BIN_EDGES,\n",
    "        include_lowest=True,\n",
    "        right=True,\n",
    "        labels=BIN_LABELS\n",
    "    )\n",
    "    old_df = old_df.dropna(subset=[\"occ_bin\"]).copy()\n",
    "    old_df[\"occ_bin\"] = old_df[\"occ_bin\"].astype(\n",
    "        pd.CategoricalDtype(categories=BIN_LABELS, ordered=True)\n",
    "    )\n",
    "\n",
    "    dfs_old[model_name] = old_df\n",
    "\n",
    "# =========================\n",
    "# Rank-Pearson correlation: Pearson(ranks)\n",
    "# (This is Spearman's rho)\n",
    "# Filter: occupancy > 20%\n",
    "# =========================\n",
    "\n",
    "OCC_THRESHOLD = 30.0  # <-- THIS is what your boss asked for\n",
    "\n",
    "def pearson_r(x: np.ndarray, y: np.ndarray) -> float:\n",
    "    \"\"\"Standard Pearson correlation on raw values.\"\"\"\n",
    "    x = pd.Series(x).astype(float)\n",
    "    y = pd.Series(y).astype(float)\n",
    "    return float(x.corr(y, method=\"pearson\"))\n",
    "\n",
    "def rank_pearson_r(x: np.ndarray, y: np.ndarray, tie_method: str = \"average\") -> float:\n",
    "    \"\"\"\n",
    "    \"Ranking Pearson correlation\" = Pearson correlation of the ranks.\n",
    "    This is Spearman's rho by definition.\n",
    "    tie_method: 'average' (default), 'min', 'max', 'dense', 'first'\n",
    "    \"\"\"\n",
    "    x = pd.Series(x).astype(float).rank(method=tie_method)\n",
    "    y = pd.Series(y).astype(float).rank(method=tie_method)\n",
    "    return float(x.corr(y, method=\"pearson\"))\n",
    "\n",
    "print(\"\\n==============================\")\n",
    "print(f\"Rank-Pearson (Pearson of ranks) and Pearson (raw), filtering occupancy > {OCC_THRESHOLD}%\")\n",
    "print(\"==============================\")\n",
    "\n",
    "rows = []\n",
    "aligned_per_model = {}\n",
    "\n",
    "for model_name in models_in_order:\n",
    "    # NEW\n",
    "    new_df = dfs_all[model_name][[\"id_key\", \"high_occupancy\", \"prob\"]].copy()\n",
    "    new_df = new_df.rename(columns={\"prob\": \"prob_new\"})\n",
    "    new_df[\"high_occupancy\"] = pd.to_numeric(new_df[\"high_occupancy\"], errors=\"coerce\")\n",
    "    new_df[\"prob_new\"] = pd.to_numeric(new_df[\"prob_new\"], errors=\"coerce\")\n",
    "    new_df = new_df.dropna(subset=[\"high_occupancy\", \"prob_new\"]).copy()\n",
    "\n",
    "    # OLD\n",
    "    old_df = dfs_old[model_name][[\"id_key\", \"high_occupancy\", \"prob_old\"]].copy()\n",
    "    old_df[\"high_occupancy\"] = pd.to_numeric(old_df[\"high_occupancy\"], errors=\"coerce\")\n",
    "    old_df[\"prob_old\"] = pd.to_numeric(old_df[\"prob_old\"], errors=\"coerce\")\n",
    "    old_df = old_df.dropna(subset=[\"high_occupancy\", \"prob_old\"]).copy()\n",
    "\n",
    "    # Align by id_key\n",
    "    merged = pd.merge(old_df, new_df[[\"id_key\", \"prob_new\"]], on=\"id_key\", how=\"inner\")\n",
    "\n",
    "    # Apply occupancy filter\n",
    "    merged = merged[merged[\"high_occupancy\"] > OCC_THRESHOLD].copy()\n",
    "\n",
    "    aligned_per_model[model_name] = merged\n",
    "\n",
    "    if len(merged) < 3:\n",
    "        pear_old = pear_new = np.nan\n",
    "        rpear_old = rpear_new = np.nan\n",
    "        rpear_old_vs_new = np.nan\n",
    "        n = len(merged)\n",
    "    else:\n",
    "        x = merged[\"high_occupancy\"].values\n",
    "        y_old = merged[\"prob_old\"].values\n",
    "        y_new = merged[\"prob_new\"].values\n",
    "\n",
    "        # raw Pearson (optional)\n",
    "        pear_old = pearson_r(x, y_old)\n",
    "        pear_new = pearson_r(x, y_new)\n",
    "\n",
    "        # \"ranking Pearson\" (what was requested)\n",
    "        rpear_old = rank_pearson_r(x, y_old)   # = Spearman(occ, old_score)\n",
    "        rpear_new = rank_pearson_r(x, y_new)   # = Spearman(occ, new_score)\n",
    "\n",
    "        # agreement between old vs new scores in rank space (often useful)\n",
    "        rpear_old_vs_new = rank_pearson_r(y_old, y_new)\n",
    "        n = len(merged)\n",
    "\n",
    "    rows.append({\n",
    "        \"model\": model_name,\n",
    "        \"n_filtered_aligned\": int(n),\n",
    "\n",
    "        # Raw Pearson\n",
    "        \"pearson_old_raw\": pear_old,\n",
    "        \"pearson_new_raw\": pear_new,\n",
    "\n",
    "        # Rank-Pearson (Pearson of ranks) == Spearman\n",
    "        \"rankPearson_old\": rpear_old,\n",
    "        \"rankPearson_new\": rpear_new,\n",
    "        \"rankPearson_old_vs_new\": rpear_old_vs_new,\n",
    "    })\n",
    "\n",
    "    print(f\"\\n{model_name}: n={n}\")\n",
    "    if n < 3:\n",
    "        print(\"  (n<3) correlations not computed\")\n",
    "    else:\n",
    "        print(f\"  RAW Pearson(occ, OLD score): {pear_old:.4f}\")\n",
    "        print(f\"  RAW Pearson(occ, NEW score): {pear_new:.4f}\")\n",
    "        print(f\"  Rank-Pearson(occ, OLD score): {rpear_old:.4f}  (Pearson of ranks)\")\n",
    "        print(f\"  Rank-Pearson(occ, NEW score): {rpear_new:.4f}  (Pearson of ranks)\")\n",
    "        print(f\"  Rank-Pearson(OLD score, NEW score): {rpear_old_vs_new:.4f}\")\n",
    "\n",
    "summary_df = pd.DataFrame(rows)\n",
    "print(\"\\nSummary:\")\n",
    "print(summary_df.to_string(index=False))\n",
    "\n",
    "\n",
    "# =========================\n",
    "# Rank vs Rank scatter plots (occupancy vs score)\n",
    "# OLD on top row, NEW on bottom row\n",
    "# =========================\n",
    "\n",
    "fig, axes = plt.subplots(\n",
    "    nrows=2,\n",
    "    ncols=len(models_in_order),\n",
    "    figsize=(22, 10),\n",
    "    sharex=False,\n",
    "    sharey=\"row\"\n",
    ")\n",
    "\n",
    "if len(models_in_order) == 1:\n",
    "    axes = np.array([[axes[0]], [axes[1]]])\n",
    "\n",
    "for col_idx, model_name in enumerate(models_in_order):\n",
    "    merged = aligned_per_model.get(model_name, pd.DataFrame())\n",
    "\n",
    "    ax_old = axes[0, col_idx]\n",
    "    ax_new = axes[1, col_idx]\n",
    "\n",
    "    ax_old.set_title(f\"{model_name}  OLD (rank vs rank)\")\n",
    "    ax_new.set_title(f\"{model_name}  NEW (rank vs rank)\")\n",
    "\n",
    "    if merged is None or merged.empty or len(merged) < 3:\n",
    "        ax_old.text(0.5, 0.5, \"Insufficient data\", ha=\"center\", va=\"center\", transform=ax_old.transAxes)\n",
    "        ax_new.text(0.5, 0.5, \"Insufficient data\", ha=\"center\", va=\"center\", transform=ax_new.transAxes)\n",
    "        continue\n",
    "\n",
    "    # Raw values\n",
    "    x = merged[\"high_occupancy\"].values\n",
    "    y_old = merged[\"prob_old\"].values\n",
    "    y_new = merged[\"prob_new\"].values\n",
    "\n",
    "    # Ranks\n",
    "    x_rank = pd.Series(x).rank(method=\"average\").values\n",
    "    y_old_rank = pd.Series(y_old).rank(method=\"average\").values\n",
    "    y_new_rank = pd.Series(y_new).rank(method=\"average\").values\n",
    "\n",
    "    # Scatter\n",
    "    ax_old.scatter(x_rank, y_old_rank, s=18, alpha=0.7)\n",
    "    ax_new.scatter(x_rank, y_new_rank, s=18, alpha=0.7)\n",
    "\n",
    "    # Rank-Pearson correlations\n",
    "    r_old = rank_pearson_r(x, y_old)\n",
    "    r_new = rank_pearson_r(x, y_new)\n",
    "\n",
    "    ax_old.text(\n",
    "        0.02, 0.95,\n",
    "        f\"rank-Pearson r = {r_old:.3f}\\nn = {len(merged)}\",\n",
    "        transform=ax_old.transAxes,\n",
    "        ha=\"left\", va=\"top\"\n",
    "    )\n",
    "\n",
    "    ax_new.text(\n",
    "        0.02, 0.95,\n",
    "        f\"rank-Pearson r = {r_new:.3f}\\nn = {len(merged)}\",\n",
    "        transform=ax_new.transAxes,\n",
    "        ha=\"left\", va=\"top\"\n",
    "    )\n",
    "\n",
    "    # Axis labels\n",
    "    if col_idx == 0:\n",
    "        ax_old.set_ylabel(\"Rank(score)  OLD\")\n",
    "        ax_new.set_ylabel(\"Rank(score)  NEW\")\n",
    "\n",
    "    ax_new.set_xlabel(\"Rank(residue occupancy)\")\n",
    "\n",
    "    for ax in [ax_old, ax_new]:\n",
    "        ax.grid(True, alpha=0.25)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# =========================\n",
    "# Find OCC samples missing from model results\n",
    "# =========================\n",
    "\n",
    "# All OCC ids\n",
    "occ_ids = set(occ[\"id_key\"])\n",
    "\n",
    "# All ids present in any model (union across models)\n",
    "model_ids = set()\n",
    "for model_name in models_in_order:\n",
    "    model_ids |= set(dfs_all[model_name][\"id_key\"])\n",
    "\n",
    "missing_ids = sorted(occ_ids - model_ids)\n",
    "\n",
    "print(\"\\n==============================\")\n",
    "print(\"OCC samples NOT found in any model results\")\n",
    "print(\"==============================\")\n",
    "print(f\"Missing count: {len(missing_ids)}\")\n",
    "\n",
    "for mid in missing_ids:\n",
    "    print(mid)\n",
    "\n",
    "# =========================\n",
    "# Plot: OLD (top) vs NEW (bottom) per model\n",
    "# =========================\n",
    "fig, axes = plt.subplots(\n",
    "    nrows=2,\n",
    "    ncols=len(models_in_order),\n",
    "    figsize=(22, 10),\n",
    "    sharex=True,\n",
    "    sharey=\"row\"\n",
    ")\n",
    "\n",
    "if len(models_in_order) == 1:\n",
    "    axes = np.array([[axes[0]], [axes[1]]])\n",
    "\n",
    "colors = [\"#FF6B6B\", \"#FFA36B\", \"#6BFF8D\", \"#6BA3FF\"]  # GNN, GAT, 3D CNN, GCN\n",
    "MODEL_COLORS = {\n",
    "    \"GNN\": colors[0],\n",
    "    \"GAT\": colors[1],\n",
    "    \"GCN\": colors[3],\n",
    "}\n",
    "\n",
    "for col_idx, model_name in enumerate(models_in_order):\n",
    "\n",
    "    color = MODEL_COLORS[model_name]\n",
    "\n",
    "    # =====================\n",
    "    # TOP: OLD (from OCC)\n",
    "    # =====================\n",
    "    ax_old = axes[0, col_idx]\n",
    "    old_df = dfs_old.get(model_name)\n",
    "\n",
    "    old_data = [\n",
    "        old_df.loc[old_df[\"occ_bin\"] == b, \"prob_old\"].values\n",
    "        for b in BIN_LABELS\n",
    "    ]\n",
    "    old_counts = [len(a) for a in old_data]\n",
    "    old_means = [np.mean(a) if len(a) else np.nan for a in old_data]\n",
    "\n",
    "    # bars behind\n",
    "    ax2_old = ax_old.twinx()\n",
    "    ax2_old.bar(\n",
    "        BIN_POS,\n",
    "        old_counts,\n",
    "        width=BIN_WIDTHS,\n",
    "        alpha=0.25,\n",
    "        align=\"center\",\n",
    "        zorder=0\n",
    "    )\n",
    "    ax2_old.set_ylim(0, max([1] + old_counts) * 1.15)\n",
    "    ax2_old.set_ylabel(\"# samples (OLD)\")\n",
    "\n",
    "    bp_old = ax_old.boxplot(\n",
    "        old_data,\n",
    "        positions=BIN_POS,\n",
    "        widths=BIN_WIDTHS,\n",
    "        patch_artist=True,\n",
    "        showfliers=True,\n",
    "        manage_ticks=False,\n",
    "        zorder=3\n",
    "    )\n",
    "\n",
    "    for box in bp_old[\"boxes\"]:\n",
    "        box.set_facecolor(color)\n",
    "        box.set_edgecolor(\"black\")\n",
    "        box.set_alpha(0.6)\n",
    "\n",
    "    for k in [\"whiskers\", \"caps\", \"medians\"]:\n",
    "        for line in bp_old[k]:\n",
    "            line.set_color(\"black\")\n",
    "    for m in bp_old[\"medians\"]:\n",
    "        m.set_linewidth(2)\n",
    "\n",
    "    ax_old.plot(\n",
    "        BIN_POS, old_means,\n",
    "        marker=\"o\", linestyle=\"--\", linewidth=2,\n",
    "        label=\"OLD mean\", zorder=4\n",
    "    )\n",
    "\n",
    "    ax_old.set_title(f\"{model_name}  OLD\")\n",
    "    if col_idx == 0:\n",
    "        ax_old.set_ylabel(\"Probability score\")\n",
    "\n",
    "    # =====================\n",
    "    # BOTTOM: NEW (Ensemble)\n",
    "    # =====================\n",
    "    ax_new = axes[1, col_idx]\n",
    "    new_df = dfs_all[model_name]\n",
    "\n",
    "    new_data = [\n",
    "        new_df.loc[new_df[\"occ_bin\"] == b, \"prob\"].values\n",
    "        for b in BIN_LABELS\n",
    "    ]\n",
    "    new_counts = [len(a) for a in new_data]\n",
    "    new_means = [np.mean(a) if len(a) else np.nan for a in new_data]\n",
    "\n",
    "    ax2_new = ax_new.twinx()\n",
    "    ax2_new.bar(\n",
    "        BIN_POS,\n",
    "        new_counts,\n",
    "        width=BIN_WIDTHS,\n",
    "        alpha=0.25,\n",
    "        align=\"center\",\n",
    "        zorder=0\n",
    "    )\n",
    "    ax2_new.set_ylim(0, max([1] + new_counts) * 1.15)\n",
    "    ax2_new.set_ylabel(\"# samples (NEW)\")\n",
    "\n",
    "    bp_new = ax_new.boxplot(\n",
    "        new_data,\n",
    "        positions=BIN_POS,\n",
    "        widths=BIN_WIDTHS,\n",
    "        patch_artist=True,\n",
    "        showfliers=True,\n",
    "        manage_ticks=False,\n",
    "        zorder=3\n",
    "    )\n",
    "\n",
    "    for box in bp_new[\"boxes\"]:\n",
    "        box.set_facecolor(color)\n",
    "        box.set_edgecolor(\"black\")\n",
    "        box.set_alpha(0.85)\n",
    "\n",
    "    for k in [\"whiskers\", \"caps\", \"medians\"]:\n",
    "        for line in bp_new[k]:\n",
    "            line.set_color(\"black\")\n",
    "    for m in bp_new[\"medians\"]:\n",
    "        m.set_linewidth(2)\n",
    "\n",
    "    ax_new.plot(\n",
    "        BIN_POS, new_means,\n",
    "        marker=\"o\", linestyle=\"-\", linewidth=2,\n",
    "        label=\"NEW mean\", zorder=4\n",
    "    )\n",
    "\n",
    "    ax_new.set_title(f\"{model_name}  NEW\")\n",
    "    ax_new.set_xlabel(\"Residue occupancy\")\n",
    "    ax_new.set_xlim(0, 100)\n",
    "    ax_new.set_xticks(XTICKS)\n",
    "    ax_new.set_xticklabels([str(int(t)) for t in XTICKS])\n",
    "\n",
    "    if col_idx == 0:\n",
    "        ax_new.set_ylabel(\"Probability score\")\n",
    "\n",
    "    # vertical bin boundaries\n",
    "    for edge in BIN_EDGES:\n",
    "        ax_old.axvline(edge, linestyle=\"--\", linewidth=0.8, alpha=0.4)\n",
    "        ax_new.axvline(edge, linestyle=\"--\", linewidth=0.8, alpha=0.4)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# =========================\n",
    "# Sanity prints\n",
    "# =========================\n",
    "for model_name in models_in_order:\n",
    "    print(\n",
    "        f\"{model_name}: 1_16={len(dfs_1_16[model_name])}, \"\n",
    "        f\"sep={len(dfs_sep[model_name])}, \"\n",
    "        f\"anton={len(dfs_anton[model_name])}, \"\n",
    "        f\"combined={len(dfs_all[model_name])}\"\n",
    "    )\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bio-ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
